{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90387ad24a564031ba14d79680602ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b739c55d87584cf9ae6a58221835d904",
              "IPY_MODEL_3ca5ea4020cb4255a9804df1c2eda63b",
              "IPY_MODEL_2d93fd205b0845518f9397999f1d6e2c"
            ],
            "layout": "IPY_MODEL_907b966bbb2c443ca7eee7d1c8623058"
          }
        },
        "b739c55d87584cf9ae6a58221835d904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d1b1c1a66346e880bf0de305d1971c",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f6e7800b1a4ee8a2c43e638bef26ad",
            "value": "README.md: 100%"
          }
        },
        "3ca5ea4020cb4255a9804df1c2eda63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a6b7f214cea45c2a5f090b6e12391a0",
            "max": 2390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ec5c96bd13d4ee2b98e30841bf1c009",
            "value": 2390
          }
        },
        "2d93fd205b0845518f9397999f1d6e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918ef5e6c23444cda1b4cee2f984a3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_7125ffeaab0044cb87f0e79960fadbff",
            "value": " 2.39k/2.39k [00:00&lt;00:00, 62.7kB/s]"
          }
        },
        "907b966bbb2c443ca7eee7d1c8623058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d1b1c1a66346e880bf0de305d1971c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f6e7800b1a4ee8a2c43e638bef26ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a6b7f214cea45c2a5f090b6e12391a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec5c96bd13d4ee2b98e30841bf1c009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918ef5e6c23444cda1b4cee2f984a3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7125ffeaab0044cb87f0e79960fadbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35b2722d1e62415a8daa9e70e8cd13f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_328043efcde8417ba22e148804e0118b",
              "IPY_MODEL_0a18df5baf5c4f07aab40dce8baccee6",
              "IPY_MODEL_56b23980b3dd4ecd99c36d252eeb6f44"
            ],
            "layout": "IPY_MODEL_80d9567cdce2405080c07cb33b144ba6"
          }
        },
        "328043efcde8417ba22e148804e0118b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a8c655c43f49f6a392796b335d1d60",
            "placeholder": "​",
            "style": "IPY_MODEL_9a757d082bfa4c0fb1afd1eac6231d65",
            "value": "fairface.py: 100%"
          }
        },
        "0a18df5baf5c4f07aab40dce8baccee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02209cdcf5a24365a1d8201968059724",
            "max": 2068,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20726e040008472a9817006eadfa98db",
            "value": 2068
          }
        },
        "56b23980b3dd4ecd99c36d252eeb6f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1c5aebfabaa4195b5f39dc36382742a",
            "placeholder": "​",
            "style": "IPY_MODEL_a6e825bd947b4ef0882b66b1e7e2573d",
            "value": " 2.07k/2.07k [00:00&lt;00:00, 50.2kB/s]"
          }
        },
        "80d9567cdce2405080c07cb33b144ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a8c655c43f49f6a392796b335d1d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a757d082bfa4c0fb1afd1eac6231d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02209cdcf5a24365a1d8201968059724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20726e040008472a9817006eadfa98db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1c5aebfabaa4195b5f39dc36382742a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e825bd947b4ef0882b66b1e7e2573d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d435a16fa0d402488bb063d3b359e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b39fbc4c7d6447889395411b33fccb0b",
              "IPY_MODEL_96316c05b7064f179ec179f01aaa0665",
              "IPY_MODEL_9296fba4287b41b8b0c6bdc621e303c2"
            ],
            "layout": "IPY_MODEL_fbf2e147b10148ebb4215f69674c83b5"
          }
        },
        "b39fbc4c7d6447889395411b33fccb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e54307de61b4ee8ba262078c035441e",
            "placeholder": "​",
            "style": "IPY_MODEL_850359ece1404bf99a6a29d93e111f48",
            "value": "train.pt: 100%"
          }
        },
        "96316c05b7064f179ec179f01aaa0665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46d42a786014ceea0a8d7ebb5972eae",
            "max": 513848604,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_375a9523dd5342a8a1d96ec5a49eb2bd",
            "value": 513848604
          }
        },
        "9296fba4287b41b8b0c6bdc621e303c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab78cc204cd418289e9fa132fc3425d",
            "placeholder": "​",
            "style": "IPY_MODEL_4bb5c1d18a6548f79e3a8976c4489536",
            "value": " 514M/514M [00:07&lt;00:00, 71.9MB/s]"
          }
        },
        "fbf2e147b10148ebb4215f69674c83b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e54307de61b4ee8ba262078c035441e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850359ece1404bf99a6a29d93e111f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e46d42a786014ceea0a8d7ebb5972eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375a9523dd5342a8a1d96ec5a49eb2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dab78cc204cd418289e9fa132fc3425d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb5c1d18a6548f79e3a8976c4489536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4963cfab629d415a805db62d24123122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8c284945a9c43a9babbeb958f9078e8",
              "IPY_MODEL_e4428fbe1bcf4ce083f9a0b9a4c0d7fd",
              "IPY_MODEL_d23b9572e8e14e16a36252a04beba04b"
            ],
            "layout": "IPY_MODEL_3a9532333f234c4a81b0bf6d1c1925ac"
          }
        },
        "d8c284945a9c43a9babbeb958f9078e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8079ccab8eca4d09a8d6e086322c637a",
            "placeholder": "​",
            "style": "IPY_MODEL_5ff38c60b02a4747a895352eec9d6971",
            "value": "val.pt: 100%"
          }
        },
        "e4428fbe1bcf4ce083f9a0b9a4c0d7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74350bd61de4da88a0604343b721d44",
            "max": 64980802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b29f8382ba64621b082c2f211881306",
            "value": 64980802
          }
        },
        "d23b9572e8e14e16a36252a04beba04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be75502b91640e18d1800c5da267642",
            "placeholder": "​",
            "style": "IPY_MODEL_ff73942d5e4d42cbb0c8b5d2cd966010",
            "value": " 65.0M/65.0M [00:01&lt;00:00, 62.8MB/s]"
          }
        },
        "3a9532333f234c4a81b0bf6d1c1925ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8079ccab8eca4d09a8d6e086322c637a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff38c60b02a4747a895352eec9d6971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74350bd61de4da88a0604343b721d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b29f8382ba64621b082c2f211881306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5be75502b91640e18d1800c5da267642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff73942d5e4d42cbb0c8b5d2cd966010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "927251ad1ae74435b775c3dc64f731f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2274da0cdc7246f0934007fdc4e933cb",
              "IPY_MODEL_4a0a89311d2c435c89ef662409e9f3b7",
              "IPY_MODEL_bb03ef1c64234b24b9d36577d650bd60"
            ],
            "layout": "IPY_MODEL_633b520e264f4ef3b6ae1c5c8a7bee19"
          }
        },
        "2274da0cdc7246f0934007fdc4e933cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3e1e1c7a194cfc877348427ad64032",
            "placeholder": "​",
            "style": "IPY_MODEL_dcb1e551e6834c939e084be0d9c34037",
            "value": "Generating train split: "
          }
        },
        "4a0a89311d2c435c89ef662409e9f3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff5579d0e9848f1be585a18aa534570",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab6430a00135458bbd43f435220e54fd",
            "value": 1
          }
        },
        "bb03ef1c64234b24b9d36577d650bd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76341bda27446bab60c84bcac026dec",
            "placeholder": "​",
            "style": "IPY_MODEL_19c6a385bcb04aa8886d52a78098ae00",
            "value": " 86744/0 [00:07&lt;00:00, 14459.19 examples/s]"
          }
        },
        "633b520e264f4ef3b6ae1c5c8a7bee19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3e1e1c7a194cfc877348427ad64032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb1e551e6834c939e084be0d9c34037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dff5579d0e9848f1be585a18aa534570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ab6430a00135458bbd43f435220e54fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b76341bda27446bab60c84bcac026dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c6a385bcb04aa8886d52a78098ae00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd0742c92bc2458f8f85194625ef8905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0abed3e7a03f4436a651f3607b586f1b",
              "IPY_MODEL_02aaf58979b841f898b97fe62b22525a",
              "IPY_MODEL_5aa34fcb936c440aaa1b08b140d203d4"
            ],
            "layout": "IPY_MODEL_2291aeb316a64167bfbb768626290037"
          }
        },
        "0abed3e7a03f4436a651f3607b586f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4fccfcaa6a548e5aad056cc5e6152d8",
            "placeholder": "​",
            "style": "IPY_MODEL_359ff3276c474ee0934f6b0dfb48e850",
            "value": "Generating validation split: "
          }
        },
        "02aaf58979b841f898b97fe62b22525a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860d67aa543d4ec9a4a2cbf1b61f7e37",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f784ce766da4fa39d7ba6ee001fafb5",
            "value": 1
          }
        },
        "5aa34fcb936c440aaa1b08b140d203d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dde9c9e4ae14dd2a26ada53e6954b7c",
            "placeholder": "​",
            "style": "IPY_MODEL_39e7b50c9dfe402ebb4270939f6dead9",
            "value": " 10954/0 [00:00&lt;00:00, 15052.55 examples/s]"
          }
        },
        "2291aeb316a64167bfbb768626290037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fccfcaa6a548e5aad056cc5e6152d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359ff3276c474ee0934f6b0dfb48e850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "860d67aa543d4ec9a4a2cbf1b61f7e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1f784ce766da4fa39d7ba6ee001fafb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dde9c9e4ae14dd2a26ada53e6954b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e7b50c9dfe402ebb4270939f6dead9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i2OwpCVD-7V"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4L4iTlx6Z2",
        "outputId": "28351d4d-69d0-4e50-8bb6-37366561acb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Credentialed Accounts\n",
            "ACTIVE  ACCOUNT\n",
            "*       sarajameel23@gmail.com\n",
            "\n",
            "To set the active account, run:\n",
            "    $ gcloud config set account `ACCOUNT`\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default set-quota-project crested-acumen-448718-j5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huPJnFP-xJcX",
        "outputId": "1980d14d-48c8-453b-86e1-6cad6aaad321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.auth.application-default.set-quota-project) Application default credentials have not been set up. Run $ gcloud auth application-default login to set it up first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project crested-acumen-448718-j5\n",
        "!gcloud config list --format 'value(core.project)'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhMfs7I8ycsr",
        "outputId": "4c625c34-b1b5-44b7-a7d7-28fa89150d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "crested-acumen-448718-j5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl8K5R8II_wS",
        "outputId": "7168cd42-70c5-4452-ac01-cff1375dc021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "The service credentials associated with this virtual machine\n",
            "will automatically be used by Application Default\n",
            "Credentials, so it is not necessary to use this command.\n",
            "\n",
            "If you decide to proceed anyway, your user credentials may be visible\n",
            "to others with access to this virtual machine. Are you sure you want\n",
            "to authenticate with your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  y\n",
            "\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=AC1P1Fp2BCHnpmLvc20raVaRZmRkA2&prompt=consent&token_usage=remote&access_type=offline&code_challenge=mRt126EvUAcGCjVkO9gi4jwivW84SrG9PQiB6owRNVw&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0Ab_5qlkwqtQ-SKZgLsaaOlY7FwoXbtgyf9HOupW5Pa4mCgwhytwg1_pJy3HrdtCfiL_Cvg\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"crested-acumen-448718-j5\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cFwejE10LSN",
        "outputId": "f19f6afa-a00b-4aa8-f586-391c5b58cbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[component_manager]\n",
            "disable_update_check = True\n",
            "[core]\n",
            "account = sarajameel23@gmail.com\n",
            "project = crested-acumen-448718-j5\n",
            "\n",
            "Your active configuration is: [default]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-vision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "fI4iRbdT04zl",
        "outputId": "3684a707-e9f6-4ae7-f9cc-c8bcbe01d4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-vision\n",
            "  Downloading google_cloud_vision-3.10.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (5.29.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2025.1.31)\n",
            "Downloading google_cloud_vision-3.10.1-py3-none-any.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-vision\n",
            "Successfully installed google-cloud-vision-3.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "6061fcd110d8440d942b9f50ee42dc0c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "\n",
        "client = vision.ImageAnnotatorClient()\n",
        "print(\"✅ Google Cloud Vision API is ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLMcziwS0ZV6",
        "outputId": "d922e1cf-bc70-4161-d6cc-5bc8fb88e9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Google Cloud Vision API is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/AI_fairness_audit/vision-api.json\" /content/\n",
        "\n"
      ],
      "metadata": {
        "id": "CID500BY2DX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "json_path = \"/content/drive/MyDrive/AI_fairness_audit/vision-api.json\"  # Adjust if the filename is different\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = json_path\n",
        "\n",
        "print(f\"✅ JSON key set from: {json_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruopd-9d2LWq",
        "outputId": "46cad363-bd4f-4104-857a-6a2e87e2a70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JSON key set from: /content/drive/MyDrive/AI_fairness_audit/vision-api.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "\n",
        "client = vision.ImageAnnotatorClient()\n",
        "print(\"✅ Google Cloud Vision API is ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtFVhMs_2PMi",
        "outputId": "7b91b8d4-2d11-40f8-d49f-cf2cd535347e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Google Cloud Vision API is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"vision-api.json\"\n",
        "\n",
        "\n",
        "if os.path.exists(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]):\n",
        "  print(\"Authentication file found\")\n",
        "\n",
        "else:\n",
        "  print(\"file not found\")"
      ],
      "metadata": {
        "id": "kjBvYMY6u1Ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0bb5a4-dfef-45fd-8763-b666286c872b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication file found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn aequitas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OBmoP2fJO8T6",
        "outputId": "316d4048-10ca-491c-cd2b-1e8ccaeac7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting aequitas\n",
            "  Downloading aequitas-1.0.0-3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.11/dist-packages (from aequitas) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from aequitas) (6.0.2)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.13.2)\n",
            "Requirement already satisfied: altair>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (5.5.0)\n",
            "Collecting millify>=0.1.1 (from aequitas)\n",
            "  Downloading millify-0.1.1.tar.gz (1.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting optuna>=3.6.1 (from aequitas)\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aif360>=0.6.1 (from aequitas)\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lightgbm>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (4.5.0)\n",
            "Collecting fairgbm>=0.9.14 (from aequitas)\n",
            "  Downloading fairgbm-0.9.14-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hydra-core>=1.3.2 (from aequitas)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting hyperparameter-tuning>=0.3.1 (from aequitas)\n",
            "  Downloading hyperparameter_tuning-0.3.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting validators>=0.33.0 (from aequitas)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fastparquet>=2024.2.0 (from aequitas)\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2.6.0+cu124)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (1.32.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (4.13.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from fairgbm>=0.9.14->aequitas) (0.45.1)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet>=2024.2.0->aequitas) (2.9.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet>=2024.2.0->aequitas) (2025.3.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->aequitas)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->aequitas)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema (from hyperparameter-tuning>=0.3.1->aequitas)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.6.1->aequitas)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.6.1->aequitas)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.6.1->aequitas) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna>=3.6.1->aequitas) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->aequitas)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->aequitas) (1.3.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.6.1->aequitas) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->aequitas) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.6.1->aequitas) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair>=5.4.0->aequitas) (3.0.2)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aequitas-1.0.0-3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fairgbm-0.9.14-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperparameter_tuning-0.3.2-py3-none-any.whl (26 kB)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, millify\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=20a120177859a634bd90a5fdafd1446367fc282e6975dad700a9c29385e14e94\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1843 sha256=408bdcb62b90ea37ea0f70c08e707723ed6ce7a70d8c3def1c59521e082fab16\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/0d/c4/630629a3cdefdf9ce43ef4a08d17672c8e773bc3d769e828e0\n",
            "Successfully built antlr4-python3-runtime millify\n",
            "Installing collected packages: schema, millify, antlr4-python3-runtime, validators, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, alembic, optuna, nvidia-cusolver-cu12, fastparquet, fairlearn, fairgbm, aif360, hyperparameter-tuning, aequitas\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aequitas-1.0.0 aif360-0.6.1 alembic-1.15.2 antlr4-python3-runtime-4.9.3 colorlog-6.9.0 fairgbm-0.9.14 fairlearn-0.12.0 fastparquet-2024.11.0 hydra-core-1.3.2 hyperparameter-tuning-0.3.2 millify-0.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 optuna-4.2.1 schema-0.7.7 validators-0.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "8e4b3ff1339343c39d92ef9ac2bb6f79"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aequitas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_yVSSQ6PtTc",
        "outputId": "b22e565f-4138-4a4c-ef64-419787080f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aequitas in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.11/dist-packages (from aequitas) (3.10.0)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from aequitas) (6.0.2)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.13.2)\n",
            "Requirement already satisfied: altair>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (5.5.0)\n",
            "Requirement already satisfied: millify>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.1.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from aequitas) (1.14.1)\n",
            "Requirement already satisfied: optuna>=3.6.1 in /usr/local/lib/python3.11/dist-packages (from aequitas) (4.2.1)\n",
            "Requirement already satisfied: aif360>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.6.1)\n",
            "Requirement already satisfied: lightgbm>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (4.5.0)\n",
            "Requirement already satisfied: fairgbm>=0.9.14 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.9.14)\n",
            "Requirement already satisfied: fairlearn>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.12.0)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from aequitas) (1.3.2)\n",
            "Requirement already satisfied: hyperparameter-tuning>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.3.2)\n",
            "Requirement already satisfied: validators>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2.0.2)\n",
            "Requirement already satisfied: fastparquet>=2024.2.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2024.11.0)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from aequitas) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from aif360>=0.6.1->aequitas) (1.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (1.32.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from altair>=5.4.0->aequitas) (4.13.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from fairgbm>=0.9.14->aequitas) (0.45.1)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet>=2024.2.0->aequitas) (2.9.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet>=2024.2.0->aequitas) (2025.3.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->aequitas) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->aequitas) (4.9.3)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.11/dist-packages (from hyperparameter-tuning>=0.3.1->aequitas) (0.7.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.5->aequitas) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.6.1->aequitas) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.6.1->aequitas) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.6.1->aequitas) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna>=3.6.1->aequitas) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->aequitas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->aequitas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->aequitas) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->aequitas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->aequitas) (1.3.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.6.1->aequitas) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->aequitas) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360>=0.6.1->aequitas) (1.4.2)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google cloud API\n",
        "from google.cloud import vision\n",
        "\n",
        "# data handling\n",
        "import pandas as pd #Data manipulation\n",
        "import numpy as np # Numerical operations\n",
        "import os # File and directory operations\n",
        "\n",
        "# image processing\n",
        "import cv2 #OpenCV for image handling\n",
        "from PIL import Image #Pillow for image manipulation\n",
        "\n",
        "# API and Requests\n",
        "import requests #Making API calls\n",
        "from io import BytesIO #handling image data\n",
        "\n",
        "# Fairness metrics and bias analysis\n",
        "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
        "import aequitas #AI fairness toolkit\n",
        "import aequitas.bias\n",
        "from aequitas.bias import Bias #Using Bias because BiasReport is obsoulete\n",
        "print(\"fairlearn and \")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt #Datavisualization\n",
        "import seaborn as sns #Statistical plots\n",
        "\n",
        "#Utility\n",
        "from tqdm import tqdm #Progress bar for loops\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh-WJcxhLoh1",
        "outputId": "5dda854f-a8d3-49a3-a9e6-32a94dfda191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fairlearn and \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwv118Id535",
        "outputId": "dd58a1a5-2f9b-41e6-d38f-e7a8d027aaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "#Set the paths\n",
        "\n",
        "zip_path= '/content/drive/MyDrive/AI_fairness_audit/fairface-img-margin025-trainval.zip'\n",
        "extract_path= '/content/fairface_extracted'\n",
        "\n",
        "  #extract the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)\n",
        "\n",
        "\n",
        "#define paths to train and validate images\n",
        "train_path = os.path.join(extract_path, 'train')\n",
        "val_path = os.path.join(extract_path, 'val')\n",
        "\n",
        "print(\"Extraction complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN7SBJwheNyj",
        "outputId": "97859fc1-7c55-4c04-e144-3bdcbcc31cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/AI_fairness_audit/fairface-img-margin025-trainval.zip\" /content/\n"
      ],
      "metadata": {
        "id": "_VlZELgOfj5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2tA7QSUCO_H",
        "outputId": "eff63ef4-8646-4711-fc99-38c4fe20cf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#Loading the fairface dataset from huggingface\n",
        "dataset = load_dataset(\"nateraw/fairface\", split ='train', trust_remote_code=True)\n",
        "\n",
        "#Convert to a pandas dataframe\n",
        "df= dataset.to_pandas()\n",
        "\n",
        "#Displaying the first few\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "90387ad24a564031ba14d79680602ddb",
            "b739c55d87584cf9ae6a58221835d904",
            "3ca5ea4020cb4255a9804df1c2eda63b",
            "2d93fd205b0845518f9397999f1d6e2c",
            "907b966bbb2c443ca7eee7d1c8623058",
            "a4d1b1c1a66346e880bf0de305d1971c",
            "a8f6e7800b1a4ee8a2c43e638bef26ad",
            "9a6b7f214cea45c2a5f090b6e12391a0",
            "1ec5c96bd13d4ee2b98e30841bf1c009",
            "918ef5e6c23444cda1b4cee2f984a3c5",
            "7125ffeaab0044cb87f0e79960fadbff",
            "35b2722d1e62415a8daa9e70e8cd13f4",
            "328043efcde8417ba22e148804e0118b",
            "0a18df5baf5c4f07aab40dce8baccee6",
            "56b23980b3dd4ecd99c36d252eeb6f44",
            "80d9567cdce2405080c07cb33b144ba6",
            "e6a8c655c43f49f6a392796b335d1d60",
            "9a757d082bfa4c0fb1afd1eac6231d65",
            "02209cdcf5a24365a1d8201968059724",
            "20726e040008472a9817006eadfa98db",
            "c1c5aebfabaa4195b5f39dc36382742a",
            "a6e825bd947b4ef0882b66b1e7e2573d",
            "4d435a16fa0d402488bb063d3b359e92",
            "b39fbc4c7d6447889395411b33fccb0b",
            "96316c05b7064f179ec179f01aaa0665",
            "9296fba4287b41b8b0c6bdc621e303c2",
            "fbf2e147b10148ebb4215f69674c83b5",
            "4e54307de61b4ee8ba262078c035441e",
            "850359ece1404bf99a6a29d93e111f48",
            "e46d42a786014ceea0a8d7ebb5972eae",
            "375a9523dd5342a8a1d96ec5a49eb2bd",
            "dab78cc204cd418289e9fa132fc3425d",
            "4bb5c1d18a6548f79e3a8976c4489536",
            "4963cfab629d415a805db62d24123122",
            "d8c284945a9c43a9babbeb958f9078e8",
            "e4428fbe1bcf4ce083f9a0b9a4c0d7fd",
            "d23b9572e8e14e16a36252a04beba04b",
            "3a9532333f234c4a81b0bf6d1c1925ac",
            "8079ccab8eca4d09a8d6e086322c637a",
            "5ff38c60b02a4747a895352eec9d6971",
            "d74350bd61de4da88a0604343b721d44",
            "1b29f8382ba64621b082c2f211881306",
            "5be75502b91640e18d1800c5da267642",
            "ff73942d5e4d42cbb0c8b5d2cd966010",
            "927251ad1ae74435b775c3dc64f731f4",
            "2274da0cdc7246f0934007fdc4e933cb",
            "4a0a89311d2c435c89ef662409e9f3b7",
            "bb03ef1c64234b24b9d36577d650bd60",
            "633b520e264f4ef3b6ae1c5c8a7bee19",
            "7d3e1e1c7a194cfc877348427ad64032",
            "dcb1e551e6834c939e084be0d9c34037",
            "dff5579d0e9848f1be585a18aa534570",
            "ab6430a00135458bbd43f435220e54fd",
            "b76341bda27446bab60c84bcac026dec",
            "19c6a385bcb04aa8886d52a78098ae00",
            "dd0742c92bc2458f8f85194625ef8905",
            "0abed3e7a03f4436a651f3607b586f1b",
            "02aaf58979b841f898b97fe62b22525a",
            "5aa34fcb936c440aaa1b08b140d203d4",
            "2291aeb316a64167bfbb768626290037",
            "a4fccfcaa6a548e5aad056cc5e6152d8",
            "359ff3276c474ee0934f6b0dfb48e850",
            "860d67aa543d4ec9a4a2cbf1b61f7e37",
            "1f784ce766da4fa39d7ba6ee001fafb5",
            "5dde9c9e4ae14dd2a26ada53e6954b7c",
            "39e7b50c9dfe402ebb4270939f6dead9"
          ]
        },
        "id": "MoOePN6xERX0",
        "outputId": "c4aa18d2-e1ca-4be7-d0d1-fcddd109e103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90387ad24a564031ba14d79680602ddb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fairface.py:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35b2722d1e62415a8daa9e70e8cd13f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.pt:   0%|          | 0.00/514M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d435a16fa0d402488bb063d3b359e92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "val.pt:   0%|          | 0.00/65.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4963cfab629d415a805db62d24123122"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "927251ad1ae74435b775c3dc64f731f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd0742c92bc2458f8f85194625ef8905"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           img_bytes  age  gender  race\n",
            "0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    6       1     1\n",
            "1  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    4       0     2\n",
            "2  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    1       0     0\n",
            "3  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    3       0     2\n",
            "4  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    3       0     2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting img_bytes to .jpg files\n",
        "\n",
        "import io\n",
        "from PIL import Imagey\n",
        "\n",
        "#Creating a directory to store images\n",
        "image_dir= 'f\n",
        "airface_extracted'\n",
        "os.makedirs(image_dir,exist_ok=True)\n",
        "\n",
        "#Function to save image bytes as actual image files\n",
        "def save_image(row):\n",
        "  try:\n",
        "    image_bytes = row['img_bytes']\n",
        "    image= Image.open(io.BytesIO(image_bytes)) #converting bytes to image\n",
        "    image_path= os.path.join(image_dir, f\"image_{row.name}.jpg\") #saving the path\n",
        "    image.save(image_path)\n",
        "\n",
        "    #print(f\"saved:{image_path}\")\n",
        "    return image_path\n",
        "  except Exception as e:\n",
        "    print(f\"Error saving image {row.name}:{e}\")\n",
        "    return None\n",
        "\n",
        "#Applying funciton to save images and create a new 'file' column\n",
        "df[\"file\"]= df.apply(save_image, axis=1)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1s1G-OtXth6",
        "outputId": "bd2d9b2f-57e0-4b3e-dd7d-1e1cd0a79343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           img_bytes  age  gender  race  \\\n",
            "0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    6       1     1   \n",
            "1  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    4       0     2   \n",
            "2  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    1       0     0   \n",
            "3  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    3       0     2   \n",
            "4  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...    3       0     2   \n",
            "\n",
            "                             file  \n",
            "0  fairface_extracted/image_0.jpg  \n",
            "1  fairface_extracted/image_1.jpg  \n",
            "2  fairface_extracted/image_2.jpg  \n",
            "3  fairface_extracted/image_3.jpg  \n",
            "4  fairface_extracted/image_4.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will run 2 tests to make sure that the csv and the images are aligned. Since the csv file was missing from the zipfile, I used hugging face to get the csv.\n"
      ],
      "metadata": {
        "id": "X5sDwyNkRCg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1: Check if every image in the CSV exists in the folder\n",
        "\n",
        "\n",
        "\n",
        "#Listing all the images in the extracted folder\n",
        "all_image_files = set(os.listdir(image_dir))\n",
        "\n",
        "\n",
        "#Getting filenames from the CSV\n",
        "csv_images= set(df[\"file\"].apply(lambda x:os.path.basename(x)))\n",
        "\n",
        "#Finding misalignments\n",
        "missing_images = csv_images - all_image_files\n",
        "extra_images = all_image_files - csv_images\n",
        "\n",
        "#Print results\n",
        "print(f\"Missing images from the dataset: {len(missing_images)}\")\n",
        "print(f\"Extra images from the dataset: {len(extra_images)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhm_N7jy888F",
        "outputId": "db0dc002-7e78-4f80-aa6f-0db531e76596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing images from the dataset: 0\n",
            "Extra images from the dataset: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 2: Check for duplicate filenames\n",
        "\n",
        "duplicates = df[\"file\"].value_counts()\n",
        "duplicates = duplicates[duplicates > 1]\n",
        "\n",
        "if len(duplicates) > 0:\n",
        "  print(f\"Warning some images are duplicates {duplicates}\")\n",
        "\n",
        "else:\n",
        "  print(\"There are no duplicates\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqcmVXI8iNbl",
        "outputId": "0aad3159-0428-4afc-95fc-bf5d49f6316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are no duplicates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/AI_fairness_audit/vision-api.json\" /content/\n"
      ],
      "metadata": {
        "id": "0hp_0wP1gfQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"vision-api.json\"\n",
        "print(\"✅ Google Cloud authentication refreshed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ3kLAdZ8OEe",
        "outputId": "77c5049d-cf3e-4366-d031-7956b003b46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Google Cloud authentication refreshed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "\n",
        "# Initialize Google Vision client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# Select a test image\n",
        "test_image_path = os.path.join(image_dir, \"image_1.jpg\")  # Change if needed\n",
        "\n",
        "def get_face_detection(image_path):\n",
        "    \"\"\"Send image to Google Vision API and detect faces.\"\"\"\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.face_detection(image=image)\n",
        "\n",
        "        if not response.face_annotations:\n",
        "            print(\"⚠ No face detected.\")\n",
        "            return \"No face detected\"\n",
        "\n",
        "        print(\"✅ Face detected in:\", image_path)\n",
        "        return \"Face detected\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run face detection test\n",
        "result = get_face_detection(test_image_path)\n",
        "print(\"Result:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMzpMG76LszP",
        "outputId": "5fbc2752-96b0-4f42-9d3d-48665f39bd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Face detected in: fairface_extracted/image_1.jpg\n",
            "Result: Face detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = {}\n",
        "for image_file in os.listdir(image_dir):\n",
        "  image_path = os.path.join(image_dir,image_file)\n",
        "  if os.path.isfile(image_path):\n",
        "    print(f\"processing:{image_path}\")\n",
        "    all_results[image_file]= get_face_detection(image_path)\n",
        "print(\"Processing complete! Total images processed:\",len(all_results))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XkxlmVa0acbx",
        "outputId": "ff817583-a1b9-4a10-b49c-f466a48f6d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing:fairface_extracted/image_24520.jpg\n",
            "✅ Face detected in: fairface_extracted/image_24520.jpg\n",
            "processing:fairface_extracted/image_79300.jpg\n",
            "✅ Face detected in: fairface_extracted/image_79300.jpg\n",
            "processing:fairface_extracted/image_27678.jpg\n",
            "✅ Face detected in: fairface_extracted/image_27678.jpg\n",
            "processing:fairface_extracted/image_13904.jpg\n",
            "✅ Face detected in: fairface_extracted/image_13904.jpg\n",
            "processing:fairface_extracted/image_28227.jpg\n",
            "✅ Face detected in: fairface_extracted/image_28227.jpg\n",
            "processing:fairface_extracted/image_9548.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_76575.jpg\n",
            "✅ Face detected in: fairface_extracted/image_76575.jpg\n",
            "processing:fairface_extracted/image_66016.jpg\n",
            "✅ Face detected in: fairface_extracted/image_66016.jpg\n",
            "processing:fairface_extracted/image_39785.jpg\n",
            "✅ Face detected in: fairface_extracted/image_39785.jpg\n",
            "processing:fairface_extracted/image_59144.jpg\n",
            "✅ Face detected in: fairface_extracted/image_59144.jpg\n",
            "processing:fairface_extracted/image_63979.jpg\n",
            "✅ Face detected in: fairface_extracted/image_63979.jpg\n",
            "processing:fairface_extracted/image_22999.jpg\n",
            "✅ Face detected in: fairface_extracted/image_22999.jpg\n",
            "processing:fairface_extracted/image_47111.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47111.jpg\n",
            "processing:fairface_extracted/image_65637.jpg\n",
            "✅ Face detected in: fairface_extracted/image_65637.jpg\n",
            "processing:fairface_extracted/image_61616.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_59803.jpg\n",
            "✅ Face detected in: fairface_extracted/image_59803.jpg\n",
            "processing:fairface_extracted/image_49449.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_74567.jpg\n",
            "✅ Face detected in: fairface_extracted/image_74567.jpg\n",
            "processing:fairface_extracted/image_38872.jpg\n",
            "✅ Face detected in: fairface_extracted/image_38872.jpg\n",
            "processing:fairface_extracted/image_52206.jpg\n",
            "✅ Face detected in: fairface_extracted/image_52206.jpg\n",
            "processing:fairface_extracted/image_21507.jpg\n",
            "✅ Face detected in: fairface_extracted/image_21507.jpg\n",
            "processing:fairface_extracted/image_48764.jpg\n",
            "✅ Face detected in: fairface_extracted/image_48764.jpg\n",
            "processing:fairface_extracted/image_31156.jpg\n",
            "✅ Face detected in: fairface_extracted/image_31156.jpg\n",
            "processing:fairface_extracted/image_21046.jpg\n",
            "✅ Face detected in: fairface_extracted/image_21046.jpg\n",
            "processing:fairface_extracted/image_54302.jpg\n",
            "✅ Face detected in: fairface_extracted/image_54302.jpg\n",
            "processing:fairface_extracted/image_26537.jpg\n",
            "✅ Face detected in: fairface_extracted/image_26537.jpg\n",
            "processing:fairface_extracted/image_22980.jpg\n",
            "✅ Face detected in: fairface_extracted/image_22980.jpg\n",
            "processing:fairface_extracted/image_15733.jpg\n",
            "✅ Face detected in: fairface_extracted/image_15733.jpg\n",
            "processing:fairface_extracted/image_15653.jpg\n",
            "✅ Face detected in: fairface_extracted/image_15653.jpg\n",
            "processing:fairface_extracted/image_45746.jpg\n",
            "✅ Face detected in: fairface_extracted/image_45746.jpg\n",
            "processing:fairface_extracted/image_25665.jpg\n",
            "✅ Face detected in: fairface_extracted/image_25665.jpg\n",
            "processing:fairface_extracted/image_8336.jpg\n",
            "✅ Face detected in: fairface_extracted/image_8336.jpg\n",
            "processing:fairface_extracted/image_85084.jpg\n",
            "✅ Face detected in: fairface_extracted/image_85084.jpg\n",
            "processing:fairface_extracted/image_70417.jpg\n",
            "✅ Face detected in: fairface_extracted/image_70417.jpg\n",
            "processing:fairface_extracted/image_56071.jpg\n",
            "✅ Face detected in: fairface_extracted/image_56071.jpg\n",
            "processing:fairface_extracted/image_33837.jpg\n",
            "✅ Face detected in: fairface_extracted/image_33837.jpg\n",
            "processing:fairface_extracted/image_43700.jpg\n",
            "✅ Face detected in: fairface_extracted/image_43700.jpg\n",
            "processing:fairface_extracted/image_42816.jpg\n",
            "✅ Face detected in: fairface_extracted/image_42816.jpg\n",
            "processing:fairface_extracted/image_78667.jpg\n",
            "✅ Face detected in: fairface_extracted/image_78667.jpg\n",
            "processing:fairface_extracted/image_7867.jpg\n",
            "✅ Face detected in: fairface_extracted/image_7867.jpg\n",
            "processing:fairface_extracted/image_63644.jpg\n",
            "✅ Face detected in: fairface_extracted/image_63644.jpg\n",
            "processing:fairface_extracted/image_47304.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47304.jpg\n",
            "processing:fairface_extracted/image_17609.jpg\n",
            "✅ Face detected in: fairface_extracted/image_17609.jpg\n",
            "processing:fairface_extracted/image_59843.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_73370.jpg\n",
            "✅ Face detected in: fairface_extracted/image_73370.jpg\n",
            "processing:fairface_extracted/image_3792.jpg\n",
            "✅ Face detected in: fairface_extracted/image_3792.jpg\n",
            "processing:fairface_extracted/image_65739.jpg\n",
            "✅ Face detected in: fairface_extracted/image_65739.jpg\n",
            "processing:fairface_extracted/image_54865.jpg\n",
            "✅ Face detected in: fairface_extracted/image_54865.jpg\n",
            "processing:fairface_extracted/image_52112.jpg\n",
            "✅ Face detected in: fairface_extracted/image_52112.jpg\n",
            "processing:fairface_extracted/image_18407.jpg\n",
            "✅ Face detected in: fairface_extracted/image_18407.jpg\n",
            "processing:fairface_extracted/image_40036.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_20788.jpg\n",
            "✅ Face detected in: fairface_extracted/image_20788.jpg\n",
            "processing:fairface_extracted/image_73072.jpg\n",
            "✅ Face detected in: fairface_extracted/image_73072.jpg\n",
            "processing:fairface_extracted/image_50652.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50652.jpg\n",
            "processing:fairface_extracted/image_42786.jpg\n",
            "✅ Face detected in: fairface_extracted/image_42786.jpg\n",
            "processing:fairface_extracted/image_33592.jpg\n",
            "✅ Face detected in: fairface_extracted/image_33592.jpg\n",
            "processing:fairface_extracted/image_81655.jpg\n",
            "✅ Face detected in: fairface_extracted/image_81655.jpg\n",
            "processing:fairface_extracted/image_82615.jpg\n",
            "✅ Face detected in: fairface_extracted/image_82615.jpg\n",
            "processing:fairface_extracted/image_80303.jpg\n",
            "✅ Face detected in: fairface_extracted/image_80303.jpg\n",
            "processing:fairface_extracted/image_40932.jpg\n",
            "✅ Face detected in: fairface_extracted/image_40932.jpg\n",
            "processing:fairface_extracted/image_83514.jpg\n",
            "✅ Face detected in: fairface_extracted/image_83514.jpg\n",
            "processing:fairface_extracted/image_80747.jpg\n",
            "✅ Face detected in: fairface_extracted/image_80747.jpg\n",
            "processing:fairface_extracted/image_62527.jpg\n",
            "✅ Face detected in: fairface_extracted/image_62527.jpg\n",
            "processing:fairface_extracted/image_17265.jpg\n",
            "✅ Face detected in: fairface_extracted/image_17265.jpg\n",
            "processing:fairface_extracted/image_39036.jpg\n",
            "✅ Face detected in: fairface_extracted/image_39036.jpg\n",
            "processing:fairface_extracted/image_3274.jpg\n",
            "✅ Face detected in: fairface_extracted/image_3274.jpg\n",
            "processing:fairface_extracted/image_67485.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_74748.jpg\n",
            "✅ Face detected in: fairface_extracted/image_74748.jpg\n",
            "processing:fairface_extracted/image_47190.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47190.jpg\n",
            "processing:fairface_extracted/image_17257.jpg\n",
            "✅ Face detected in: fairface_extracted/image_17257.jpg\n",
            "processing:fairface_extracted/image_19446.jpg\n",
            "✅ Face detected in: fairface_extracted/image_19446.jpg\n",
            "processing:fairface_extracted/image_5860.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_61165.jpg\n",
            "✅ Face detected in: fairface_extracted/image_61165.jpg\n",
            "processing:fairface_extracted/image_64077.jpg\n",
            "✅ Face detected in: fairface_extracted/image_64077.jpg\n",
            "processing:fairface_extracted/image_70242.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_30553.jpg\n",
            "✅ Face detected in: fairface_extracted/image_30553.jpg\n",
            "processing:fairface_extracted/image_68921.jpg\n",
            "✅ Face detected in: fairface_extracted/image_68921.jpg\n",
            "processing:fairface_extracted/image_40236.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_5646.jpg\n",
            "✅ Face detected in: fairface_extracted/image_5646.jpg\n",
            "processing:fairface_extracted/image_60642.jpg\n",
            "✅ Face detected in: fairface_extracted/image_60642.jpg\n",
            "processing:fairface_extracted/image_36129.jpg\n",
            "✅ Face detected in: fairface_extracted/image_36129.jpg\n",
            "processing:fairface_extracted/image_12151.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12151.jpg\n",
            "processing:fairface_extracted/image_85203.jpg\n",
            "✅ Face detected in: fairface_extracted/image_85203.jpg\n",
            "processing:fairface_extracted/image_2401.jpg\n",
            "✅ Face detected in: fairface_extracted/image_2401.jpg\n",
            "processing:fairface_extracted/image_61810.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_57395.jpg\n",
            "✅ Face detected in: fairface_extracted/image_57395.jpg\n",
            "processing:fairface_extracted/image_7520.jpg\n",
            "✅ Face detected in: fairface_extracted/image_7520.jpg\n",
            "processing:fairface_extracted/image_34223.jpg\n",
            "✅ Face detected in: fairface_extracted/image_34223.jpg\n",
            "processing:fairface_extracted/image_73254.jpg\n",
            "✅ Face detected in: fairface_extracted/image_73254.jpg\n",
            "processing:fairface_extracted/image_29937.jpg\n",
            "✅ Face detected in: fairface_extracted/image_29937.jpg\n",
            "processing:fairface_extracted/image_53189.jpg\n",
            "✅ Face detected in: fairface_extracted/image_53189.jpg\n",
            "processing:fairface_extracted/image_57626.jpg\n",
            "✅ Face detected in: fairface_extracted/image_57626.jpg\n",
            "processing:fairface_extracted/image_17088.jpg\n",
            "✅ Face detected in: fairface_extracted/image_17088.jpg\n",
            "processing:fairface_extracted/image_85522.jpg\n",
            "✅ Face detected in: fairface_extracted/image_85522.jpg\n",
            "processing:fairface_extracted/image_49011.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_10051.jpg\n",
            "✅ Face detected in: fairface_extracted/image_10051.jpg\n",
            "processing:fairface_extracted/image_60592.jpg\n",
            "✅ Face detected in: fairface_extracted/image_60592.jpg\n",
            "processing:fairface_extracted/image_61216.jpg\n",
            "✅ Face detected in: fairface_extracted/image_61216.jpg\n",
            "processing:fairface_extracted/image_52607.jpg\n",
            "✅ Face detected in: fairface_extracted/image_52607.jpg\n",
            "processing:fairface_extracted/image_16497.jpg\n",
            "✅ Face detected in: fairface_extracted/image_16497.jpg\n",
            "processing:fairface_extracted/image_61696.jpg\n",
            "✅ Face detected in: fairface_extracted/image_61696.jpg\n",
            "processing:fairface_extracted/image_30825.jpg\n",
            "✅ Face detected in: fairface_extracted/image_30825.jpg\n",
            "processing:fairface_extracted/image_56443.jpg\n",
            "✅ Face detected in: fairface_extracted/image_56443.jpg\n",
            "processing:fairface_extracted/image_41373.jpg\n",
            "✅ Face detected in: fairface_extracted/image_41373.jpg\n",
            "processing:fairface_extracted/image_30624.jpg\n",
            "✅ Face detected in: fairface_extracted/image_30624.jpg\n",
            "processing:fairface_extracted/image_10789.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_79987.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_50922.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50922.jpg\n",
            "processing:fairface_extracted/image_45740.jpg\n",
            "✅ Face detected in: fairface_extracted/image_45740.jpg\n",
            "processing:fairface_extracted/image_40007.jpg\n",
            "✅ Face detected in: fairface_extracted/image_40007.jpg\n",
            "processing:fairface_extracted/image_38601.jpg\n",
            "✅ Face detected in: fairface_extracted/image_38601.jpg\n",
            "processing:fairface_extracted/image_14580.jpg\n",
            "✅ Face detected in: fairface_extracted/image_14580.jpg\n",
            "processing:fairface_extracted/image_5676.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_12449.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12449.jpg\n",
            "processing:fairface_extracted/image_73826.jpg\n",
            "✅ Face detected in: fairface_extracted/image_73826.jpg\n",
            "processing:fairface_extracted/image_76517.jpg\n",
            "✅ Face detected in: fairface_extracted/image_76517.jpg\n",
            "processing:fairface_extracted/image_5743.jpg\n",
            "✅ Face detected in: fairface_extracted/image_5743.jpg\n",
            "processing:fairface_extracted/image_72409.jpg\n",
            "✅ Face detected in: fairface_extracted/image_72409.jpg\n",
            "processing:fairface_extracted/image_12393.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12393.jpg\n",
            "processing:fairface_extracted/image_76781.jpg\n",
            "✅ Face detected in: fairface_extracted/image_76781.jpg\n",
            "processing:fairface_extracted/image_21147.jpg\n",
            "✅ Face detected in: fairface_extracted/image_21147.jpg\n",
            "processing:fairface_extracted/image_60464.jpg\n",
            "✅ Face detected in: fairface_extracted/image_60464.jpg\n",
            "processing:fairface_extracted/image_48429.jpg\n",
            "✅ Face detected in: fairface_extracted/image_48429.jpg\n",
            "processing:fairface_extracted/image_75545.jpg\n",
            "✅ Face detected in: fairface_extracted/image_75545.jpg\n",
            "processing:fairface_extracted/image_79374.jpg\n",
            "✅ Face detected in: fairface_extracted/image_79374.jpg\n",
            "processing:fairface_extracted/image_22950.jpg\n",
            "✅ Face detected in: fairface_extracted/image_22950.jpg\n",
            "processing:fairface_extracted/image_28460.jpg\n",
            "✅ Face detected in: fairface_extracted/image_28460.jpg\n",
            "processing:fairface_extracted/image_45295.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_1501.jpg\n",
            "✅ Face detected in: fairface_extracted/image_1501.jpg\n",
            "processing:fairface_extracted/image_75414.jpg\n",
            "✅ Face detected in: fairface_extracted/image_75414.jpg\n",
            "processing:fairface_extracted/image_47708.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47708.jpg\n",
            "processing:fairface_extracted/image_75025.jpg\n",
            "✅ Face detected in: fairface_extracted/image_75025.jpg\n",
            "processing:fairface_extracted/image_2776.jpg\n",
            "✅ Face detected in: fairface_extracted/image_2776.jpg\n",
            "processing:fairface_extracted/image_50229.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50229.jpg\n",
            "processing:fairface_extracted/image_78242.jpg\n",
            "✅ Face detected in: fairface_extracted/image_78242.jpg\n",
            "processing:fairface_extracted/image_80446.jpg\n",
            "✅ Face detected in: fairface_extracted/image_80446.jpg\n",
            "processing:fairface_extracted/image_36480.jpg\n",
            "✅ Face detected in: fairface_extracted/image_36480.jpg\n",
            "processing:fairface_extracted/image_25227.jpg\n",
            "✅ Face detected in: fairface_extracted/image_25227.jpg\n",
            "processing:fairface_extracted/image_59104.jpg\n",
            "✅ Face detected in: fairface_extracted/image_59104.jpg\n",
            "processing:fairface_extracted/image_43552.jpg\n",
            "✅ Face detected in: fairface_extracted/image_43552.jpg\n",
            "processing:fairface_extracted/image_59534.jpg\n",
            "✅ Face detected in: fairface_extracted/image_59534.jpg\n",
            "processing:fairface_extracted/image_6074.jpg\n",
            "✅ Face detected in: fairface_extracted/image_6074.jpg\n",
            "processing:fairface_extracted/image_82598.jpg\n",
            "✅ Face detected in: fairface_extracted/image_82598.jpg\n",
            "processing:fairface_extracted/image_75479.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_35548.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_50705.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50705.jpg\n",
            "processing:fairface_extracted/image_82131.jpg\n",
            "✅ Face detected in: fairface_extracted/image_82131.jpg\n",
            "processing:fairface_extracted/image_701.jpg\n",
            "✅ Face detected in: fairface_extracted/image_701.jpg\n",
            "processing:fairface_extracted/image_4726.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_51005.jpg\n",
            "✅ Face detected in: fairface_extracted/image_51005.jpg\n",
            "processing:fairface_extracted/image_44033.jpg\n",
            "✅ Face detected in: fairface_extracted/image_44033.jpg\n",
            "processing:fairface_extracted/image_47742.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47742.jpg\n",
            "processing:fairface_extracted/image_38330.jpg\n",
            "✅ Face detected in: fairface_extracted/image_38330.jpg\n",
            "processing:fairface_extracted/image_51068.jpg\n",
            "✅ Face detected in: fairface_extracted/image_51068.jpg\n",
            "processing:fairface_extracted/image_51646.jpg\n",
            "✅ Face detected in: fairface_extracted/image_51646.jpg\n",
            "processing:fairface_extracted/image_12297.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12297.jpg\n",
            "processing:fairface_extracted/image_43955.jpg\n",
            "✅ Face detected in: fairface_extracted/image_43955.jpg\n",
            "processing:fairface_extracted/image_79488.jpg\n",
            "✅ Face detected in: fairface_extracted/image_79488.jpg\n",
            "processing:fairface_extracted/image_47659.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_14570.jpg\n",
            "✅ Face detected in: fairface_extracted/image_14570.jpg\n",
            "processing:fairface_extracted/image_57737.jpg\n",
            "✅ Face detected in: fairface_extracted/image_57737.jpg\n",
            "processing:fairface_extracted/image_42070.jpg\n",
            "✅ Face detected in: fairface_extracted/image_42070.jpg\n",
            "processing:fairface_extracted/image_22758.jpg\n",
            "✅ Face detected in: fairface_extracted/image_22758.jpg\n",
            "processing:fairface_extracted/image_64575.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_73115.jpg\n",
            "✅ Face detected in: fairface_extracted/image_73115.jpg\n",
            "processing:fairface_extracted/image_40474.jpg\n",
            "✅ Face detected in: fairface_extracted/image_40474.jpg\n",
            "processing:fairface_extracted/image_43365.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_50235.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50235.jpg\n",
            "processing:fairface_extracted/image_80672.jpg\n",
            "✅ Face detected in: fairface_extracted/image_80672.jpg\n",
            "processing:fairface_extracted/image_65718.jpg\n",
            "✅ Face detected in: fairface_extracted/image_65718.jpg\n",
            "processing:fairface_extracted/image_1373.jpg\n",
            "✅ Face detected in: fairface_extracted/image_1373.jpg\n",
            "processing:fairface_extracted/image_72337.jpg\n",
            "✅ Face detected in: fairface_extracted/image_72337.jpg\n",
            "processing:fairface_extracted/image_37223.jpg\n",
            "✅ Face detected in: fairface_extracted/image_37223.jpg\n",
            "processing:fairface_extracted/image_27102.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_34940.jpg\n",
            "✅ Face detected in: fairface_extracted/image_34940.jpg\n",
            "processing:fairface_extracted/image_28323.jpg\n",
            "✅ Face detected in: fairface_extracted/image_28323.jpg\n",
            "processing:fairface_extracted/image_39662.jpg\n",
            "✅ Face detected in: fairface_extracted/image_39662.jpg\n",
            "processing:fairface_extracted/image_20765.jpg\n",
            "✅ Face detected in: fairface_extracted/image_20765.jpg\n",
            "processing:fairface_extracted/image_77341.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_83581.jpg\n",
            "✅ Face detected in: fairface_extracted/image_83581.jpg\n",
            "processing:fairface_extracted/image_30493.jpg\n",
            "✅ Face detected in: fairface_extracted/image_30493.jpg\n",
            "processing:fairface_extracted/image_67971.jpg\n",
            "✅ Face detected in: fairface_extracted/image_67971.jpg\n",
            "processing:fairface_extracted/image_69552.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_54084.jpg\n",
            "✅ Face detected in: fairface_extracted/image_54084.jpg\n",
            "processing:fairface_extracted/image_39271.jpg\n",
            "✅ Face detected in: fairface_extracted/image_39271.jpg\n",
            "processing:fairface_extracted/image_37493.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_57669.jpg\n",
            "✅ Face detected in: fairface_extracted/image_57669.jpg\n",
            "processing:fairface_extracted/image_36436.jpg\n",
            "✅ Face detected in: fairface_extracted/image_36436.jpg\n",
            "processing:fairface_extracted/image_50812.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50812.jpg\n",
            "processing:fairface_extracted/image_3710.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_18509.jpg\n",
            "✅ Face detected in: fairface_extracted/image_18509.jpg\n",
            "processing:fairface_extracted/image_72653.jpg\n",
            "✅ Face detected in: fairface_extracted/image_72653.jpg\n",
            "processing:fairface_extracted/image_20074.jpg\n",
            "✅ Face detected in: fairface_extracted/image_20074.jpg\n",
            "processing:fairface_extracted/image_62346.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_77002.jpg\n",
            "✅ Face detected in: fairface_extracted/image_77002.jpg\n",
            "processing:fairface_extracted/image_83359.jpg\n",
            "✅ Face detected in: fairface_extracted/image_83359.jpg\n",
            "processing:fairface_extracted/image_42233.jpg\n",
            "✅ Face detected in: fairface_extracted/image_42233.jpg\n",
            "processing:fairface_extracted/image_47820.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47820.jpg\n",
            "processing:fairface_extracted/image_17059.jpg\n",
            "✅ Face detected in: fairface_extracted/image_17059.jpg\n",
            "processing:fairface_extracted/image_3612.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_32344.jpg\n",
            "✅ Face detected in: fairface_extracted/image_32344.jpg\n",
            "processing:fairface_extracted/image_47605.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47605.jpg\n",
            "processing:fairface_extracted/image_29726.jpg\n",
            "✅ Face detected in: fairface_extracted/image_29726.jpg\n",
            "processing:fairface_extracted/image_64150.jpg\n",
            "✅ Face detected in: fairface_extracted/image_64150.jpg\n",
            "processing:fairface_extracted/image_81031.jpg\n",
            "✅ Face detected in: fairface_extracted/image_81031.jpg\n",
            "processing:fairface_extracted/image_30076.jpg\n",
            "✅ Face detected in: fairface_extracted/image_30076.jpg\n",
            "processing:fairface_extracted/image_16565.jpg\n",
            "✅ Face detected in: fairface_extracted/image_16565.jpg\n",
            "processing:fairface_extracted/image_33939.jpg\n",
            "✅ Face detected in: fairface_extracted/image_33939.jpg\n",
            "processing:fairface_extracted/image_78196.jpg\n",
            "✅ Face detected in: fairface_extracted/image_78196.jpg\n",
            "processing:fairface_extracted/image_66887.jpg\n",
            "✅ Face detected in: fairface_extracted/image_66887.jpg\n",
            "processing:fairface_extracted/image_35456.jpg\n",
            "✅ Face detected in: fairface_extracted/image_35456.jpg\n",
            "processing:fairface_extracted/image_46235.jpg\n",
            "✅ Face detected in: fairface_extracted/image_46235.jpg\n",
            "processing:fairface_extracted/image_8974.jpg\n",
            "✅ Face detected in: fairface_extracted/image_8974.jpg\n",
            "processing:fairface_extracted/image_75528.jpg\n",
            "✅ Face detected in: fairface_extracted/image_75528.jpg\n",
            "processing:fairface_extracted/image_5687.jpg\n",
            "✅ Face detected in: fairface_extracted/image_5687.jpg\n",
            "processing:fairface_extracted/image_47633.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47633.jpg\n",
            "processing:fairface_extracted/image_52186.jpg\n",
            "✅ Face detected in: fairface_extracted/image_52186.jpg\n",
            "processing:fairface_extracted/image_56763.jpg\n",
            "✅ Face detected in: fairface_extracted/image_56763.jpg\n",
            "processing:fairface_extracted/image_51806.jpg\n",
            "✅ Face detected in: fairface_extracted/image_51806.jpg\n",
            "processing:fairface_extracted/image_3004.jpg\n",
            "✅ Face detected in: fairface_extracted/image_3004.jpg\n",
            "processing:fairface_extracted/image_48993.jpg\n",
            "✅ Face detected in: fairface_extracted/image_48993.jpg\n",
            "processing:fairface_extracted/image_69506.jpg\n",
            "✅ Face detected in: fairface_extracted/image_69506.jpg\n",
            "processing:fairface_extracted/image_26813.jpg\n",
            "✅ Face detected in: fairface_extracted/image_26813.jpg\n",
            "processing:fairface_extracted/image_28366.jpg\n",
            "✅ Face detected in: fairface_extracted/image_28366.jpg\n",
            "processing:fairface_extracted/image_12261.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12261.jpg\n",
            "processing:fairface_extracted/image_70634.jpg\n",
            "✅ Face detected in: fairface_extracted/image_70634.jpg\n",
            "processing:fairface_extracted/image_50201.jpg\n",
            "✅ Face detected in: fairface_extracted/image_50201.jpg\n",
            "processing:fairface_extracted/image_33749.jpg\n",
            "✅ Face detected in: fairface_extracted/image_33749.jpg\n",
            "processing:fairface_extracted/image_35385.jpg\n",
            "✅ Face detected in: fairface_extracted/image_35385.jpg\n",
            "processing:fairface_extracted/image_51283.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_23557.jpg\n",
            "✅ Face detected in: fairface_extracted/image_23557.jpg\n",
            "processing:fairface_extracted/image_25809.jpg\n",
            "✅ Face detected in: fairface_extracted/image_25809.jpg\n",
            "processing:fairface_extracted/image_54418.jpg\n",
            "✅ Face detected in: fairface_extracted/image_54418.jpg\n",
            "processing:fairface_extracted/image_86096.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_62639.jpg\n",
            "✅ Face detected in: fairface_extracted/image_62639.jpg\n",
            "processing:fairface_extracted/image_47189.jpg\n",
            "✅ Face detected in: fairface_extracted/image_47189.jpg\n",
            "processing:fairface_extracted/image_14772.jpg\n",
            "✅ Face detected in: fairface_extracted/image_14772.jpg\n",
            "processing:fairface_extracted/image_40011.jpg\n",
            "✅ Face detected in: fairface_extracted/image_40011.jpg\n",
            "processing:fairface_extracted/image_43589.jpg\n",
            "✅ Face detected in: fairface_extracted/image_43589.jpg\n",
            "processing:fairface_extracted/image_6249.jpg\n",
            "✅ Face detected in: fairface_extracted/image_6249.jpg\n",
            "processing:fairface_extracted/image_56941.jpg\n",
            "✅ Face detected in: fairface_extracted/image_56941.jpg\n",
            "processing:fairface_extracted/image_71561.jpg\n",
            "✅ Face detected in: fairface_extracted/image_71561.jpg\n",
            "processing:fairface_extracted/image_12200.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12200.jpg\n",
            "processing:fairface_extracted/image_78419.jpg\n",
            "✅ Face detected in: fairface_extracted/image_78419.jpg\n",
            "processing:fairface_extracted/image_3645.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_74704.jpg\n",
            "✅ Face detected in: fairface_extracted/image_74704.jpg\n",
            "processing:fairface_extracted/image_24771.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_26729.jpg\n",
            "✅ Face detected in: fairface_extracted/image_26729.jpg\n",
            "processing:fairface_extracted/image_77839.jpg\n",
            "✅ Face detected in: fairface_extracted/image_77839.jpg\n",
            "processing:fairface_extracted/image_43951.jpg\n",
            "✅ Face detected in: fairface_extracted/image_43951.jpg\n",
            "processing:fairface_extracted/image_46560.jpg\n",
            "✅ Face detected in: fairface_extracted/image_46560.jpg\n",
            "processing:fairface_extracted/image_66549.jpg\n",
            "✅ Face detected in: fairface_extracted/image_66549.jpg\n",
            "processing:fairface_extracted/image_12406.jpg\n",
            "✅ Face detected in: fairface_extracted/image_12406.jpg\n",
            "processing:fairface_extracted/image_1562.jpg\n",
            "✅ Face detected in: fairface_extracted/image_1562.jpg\n",
            "processing:fairface_extracted/image_84892.jpg\n",
            "✅ Face detected in: fairface_extracted/image_84892.jpg\n",
            "processing:fairface_extracted/image_64069.jpg\n",
            "✅ Face detected in: fairface_extracted/image_64069.jpg\n",
            "processing:fairface_extracted/image_81491.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_17775.jpg\n",
            "⚠ No face detected.\n",
            "processing:fairface_extracted/image_54793.jpg\n",
            "✅ Face detected in: fairface_extracted/image_54793.jpg\n",
            "processing:fairface_extracted/image_83455.jpg\n",
            "✅ Face detected in: fairface_extracted/image_83455.jpg\n",
            "processing:fairface_extracted/image_79572.jpg\n",
            "✅ Face detected in: fairface_extracted/image_79572.jpg\n",
            "processing:fairface_extracted/image_76334.jpg\n",
            "✅ Face detected in: fairface_extracted/image_76334.jpg\n",
            "processing:fairface_extracted/image_79843.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9ab135793563>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"processing:{image_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mall_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_face_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing complete! Total images processed:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-a16a1da2f435>\u001b[0m in \u001b[0;36mget_face_detection\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_annotations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_helpers/decorators.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(self, image, max_results, retry, timeout, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mcopied_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_results\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopied_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         response = self.annotate_image(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_helpers/__init__.py\u001b[0m in \u001b[0;36mannotate_image\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         r = self.batch_annotate_images(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mrequests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_v1/services/image_annotator/client.py\u001b[0m in \u001b[0;36mbatch_annotate_images\u001b[0;34m(self, request, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    840\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_v1/services/image_annotator/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(list(all_results.items()), columns=[\"Image\", \"FaceDetected\"])\n",
        "df_results.to_csv(\"face_detection_partial_results.csv\", index=False)\n",
        "\n",
        "print(\"✅ Saved progress! Partial results stored.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyBpnBcrrBil",
        "outputId": "0eff0d80-42a5-4b80-e47c-cbd568e9069d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved progress! Partial results stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"✅ Images processed so far: {len(all_results)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeB9yYqzqxfr",
        "outputId": "dec546d4-8c95-4fe5-e457-e2a76db37a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Images processed so far: 262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(list(all_results.items()), columns=[\"Image\", \"FaceDetected\"])\n",
        "df_results.to_csv(\"face_detection_results.csv\", index=False)\n",
        "print(\"✅ Results saved to face_detection_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sm3yo2A0_bg",
        "outputId": "b8160d4f-38a1-4e86-e5af-c77f01573a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Results saved to face_detection_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_results[\"FaceDetected\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS6-Dfw81C3E",
        "outputId": "d17f1fac-f4af-43f0-d4dd-a694b10ee991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FaceDetected\n",
            "Face detected       228\n",
            "No face detected     34\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_results[\"FaceDetected\"].value_counts().plot(kind=\"bar\", color=[\"green\", \"red\"])\n",
        "plt.title(\"Face Detection Results\")\n",
        "plt.xlabel(\"Detection Status\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gHBbp34a1W32",
        "outputId": "5b35436d-c4fd-41ef-9c2d-f495b94d0dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "\n",
        "# Initialize Google Vision API Client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "def get_gender_classification(image_path):\n",
        "    \"\"\"Sends an image to Google Vision API for gender classification.\"\"\"\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.label_detection(image=image)  # Get labels from Google Vision\n",
        "\n",
        "        labels = response.label_annotations\n",
        "        label_descriptions = [label.description.lower() for label in labels]\n",
        "\n",
        "        # Check for gender-related keywords\n",
        "        if \"man\" in label_descriptions or \"male\" in label_descriptions:\n",
        "            return \"Male\"\n",
        "        elif \"woman\" in label_descriptions or \"female\" in label_descriptions:\n",
        "            return \"Female\"\n",
        "        else:\n",
        "            return \"Unclear\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {image_path}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Hl1Kxybe3m3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the face detection results\n",
        "df_faces = pd.read_csv(\"face_detection_results.csv\")\n",
        "\n",
        "# Filter only the images where a face was detected\n",
        "df_detected_faces = df_faces[df_faces[\"FaceDetected\"] == \"Face detected\"]\n",
        "\n",
        "# Dictionary to store gender classification results\n",
        "gender_results = {}\n",
        "\n",
        "# Loop through detected faces\n",
        "for image_file in df_detected_faces[\"Image\"]:\n",
        "    image_path = os.path.join(image_dir, image_file)  # Get full path\n",
        "    print(f\"🔄 Processing gender classification for: {image_path}\")\n",
        "\n",
        "    gender = get_gender_classification(image_path)\n",
        "    gender_results[image_file] = gender\n",
        "\n",
        "print(\"✅ Gender classification complete! Total images processed:\", len(gender_results))\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_gender_results = pd.DataFrame(list(gender_results.items()), columns=[\"Image\", \"PredictedGender\"])\n",
        "\n",
        "# Save results to CSV\n",
        "df_gender_results.to_csv(\"gender_classification_results.csv\", index=False)\n",
        "print(\"✅ Results saved to gender_classification_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNwFjrH03ySJ",
        "outputId": "365425de-61f7-4318-9145-3a3e2793b9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing gender classification for: fairface_extracted/image_24520.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_79300.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_27678.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_13904.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_28227.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_76575.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_66016.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_39785.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_59144.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_63979.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_22999.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47111.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_65637.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_59803.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_74567.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_38872.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_52206.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_21507.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_48764.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_31156.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_21046.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_54302.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_26537.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_22980.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_15733.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_15653.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_45746.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_25665.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_8336.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_85084.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_70417.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_56071.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_33837.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_43700.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_42816.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_78667.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_7867.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_63644.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47304.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_17609.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_73370.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_3792.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_65739.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_54865.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_52112.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_18407.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_20788.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_73072.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50652.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_42786.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_33592.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_81655.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_82615.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_80303.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_40932.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_83514.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_80747.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_62527.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_17265.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_39036.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_3274.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_74748.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47190.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_17257.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_19446.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_61165.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_64077.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_30553.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_68921.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_5646.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_60642.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_36129.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12151.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_85203.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_2401.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_57395.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_7520.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_34223.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_73254.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_29937.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_53189.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_57626.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_17088.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_85522.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_10051.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_60592.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_61216.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_52607.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_16497.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_61696.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_30825.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_56443.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_41373.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_30624.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50922.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_45740.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_40007.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_38601.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_14580.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12449.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_73826.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_76517.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_5743.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_72409.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12393.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_76781.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_21147.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_60464.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_48429.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_75545.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_79374.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_22950.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_28460.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_1501.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_75414.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47708.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_75025.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_2776.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50229.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_78242.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_80446.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_36480.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_25227.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_59104.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_43552.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_59534.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_6074.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_82598.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50705.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_82131.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_701.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_51005.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_44033.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47742.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_38330.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_51068.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_51646.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12297.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_43955.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_79488.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_14570.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_57737.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_42070.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_22758.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_73115.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_40474.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50235.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_80672.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_65718.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_1373.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_72337.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_37223.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_34940.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_28323.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_39662.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_20765.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_83581.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_30493.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_67971.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_54084.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_39271.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_57669.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_36436.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50812.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_18509.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_72653.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_20074.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_77002.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_83359.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_42233.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47820.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_17059.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_32344.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47605.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_29726.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_64150.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_81031.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_30076.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_16565.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_33939.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_78196.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_66887.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_35456.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_46235.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_8974.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_75528.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_5687.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47633.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_52186.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_56763.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_51806.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_3004.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_48993.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_69506.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_26813.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_28366.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12261.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_70634.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_50201.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_33749.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_35385.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_23557.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_25809.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_54418.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_62639.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_47189.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_14772.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_40011.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_43589.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_6249.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_56941.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_71561.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12200.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_78419.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_74704.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_26729.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_77839.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_43951.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_46560.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_66549.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_12406.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_1562.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_84892.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_64069.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_54793.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_83455.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_79572.jpg\n",
            "🔄 Processing gender classification for: fairface_extracted/image_76334.jpg\n",
            "✅ Gender classification complete! Total images processed: 228\n",
            "✅ Results saved to gender_classification_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "client = vision.ImageAnnotatorClient()\n"
      ],
      "metadata": {
        "id": "o3xxNTTcLVFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = \"fairface_extracted/image_1.jpg\"\n",
        "\n",
        "with open(test_image_path, \"rb\") as img_file:\n",
        "    content = img_file.read()\n",
        "\n",
        "image = vision.Image(content=content)\n",
        "response = client.label_detection(image=image, timeout=10)\n",
        "\n",
        "for label in response.label_annotations:\n",
        "    print(f\"{label.description} ({label.score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBEjGRJYLaSy",
        "outputId": "1e4b01fb-9361-44ab-d066-4f8e77b8f9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cheek (0.99)\n",
            "Eyebrow (0.99)\n",
            "Lips (0.98)\n",
            "Forehead (0.98)\n",
            "Temple (0.96)\n",
            "Black hair (0.96)\n",
            "Facial expression (0.94)\n",
            "Eyelash (0.94)\n",
            "Close-up (0.86)\n",
            "Happiness (0.80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gender_labels_only(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as img_file:\n",
        "            content = img_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.label_detection(image=image, timeout=10)\n",
        "\n",
        "        labels = [label.description for label in response.label_annotations]\n",
        "        print(f\"Labels for {image_path}:\\n\", labels)\n",
        "        return labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test it\n",
        "get_gender_labels_only(\"fairface_extracted/image_1.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgEYE0NvKUvZ",
        "outputId": "89eb422c-6808-4aee-e540-7b53ac91d1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels for fairface_extracted/image_1.jpg:\n",
            " ['Cheek', 'Eyebrow', 'Lips', 'Forehead', 'Temple', 'Black hair', 'Facial expression', 'Eyelash', 'Close-up', 'Happiness']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cheek',\n",
              " 'Eyebrow',\n",
              " 'Lips',\n",
              " 'Forehead',\n",
              " 'Temple',\n",
              " 'Black hair',\n",
              " 'Facial expression',\n",
              " 'Eyelash',\n",
              " 'Close-up',\n",
              " 'Happiness']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV we previously created\n",
        "df_faces = pd.read_csv(\"face_detection_results.csv\")\n",
        "\n",
        "# Filter for images where a face was detected\n",
        "df_detected = df_faces[df_faces[\"FaceDetected\"] == \"Face detected\"].copy()\n",
        "\n",
        "print(f\"✅ Total images with detected faces: {len(df_detected)}\")\n",
        "print(df_detected.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1Zw0TmdNCk-",
        "outputId": "2b92248f-54dc-44c9-be4a-1090035c18c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total images with detected faces: 228\n",
            "             Image   FaceDetected\n",
            "0  image_24520.jpg  Face detected\n",
            "1  image_79300.jpg  Face detected\n",
            "2  image_27678.jpg  Face detected\n",
            "3  image_13904.jpg  Face detected\n",
            "4  image_28227.jpg  Face detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize result dictionary\n",
        "gender_results = {}\n",
        "\n",
        "for image_file in df_detected[\"Image\"]:\n",
        "    image_path = os.path.join(\"fairface_extracted\", image_file)\n",
        "    print(f\"🔄 Classifying gender in: {image_path}\")\n",
        "\n",
        "    gender = get_gender_classification(image_path)\n",
        "    gender_results[image_file] = gender\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-trdqBlZRtxc",
        "outputId": "f54ce47b-ee62-4b4c-d2a8-31964893756a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Classifying gender in: fairface_extracted/image_24520.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79300.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_27678.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_13904.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28227.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76575.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_66016.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39785.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59144.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_63979.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22999.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47111.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_65637.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59803.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_74567.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_38872.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52206.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_21507.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_48764.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_31156.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_21046.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54302.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_26537.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22980.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_15733.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_15653.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_45746.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_25665.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_8336.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_85084.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_70417.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56071.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33837.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43700.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42816.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78667.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_7867.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_63644.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47304.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17609.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73370.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_3792.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_65739.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54865.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52112.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_18407.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_20788.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73072.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50652.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42786.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33592.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_81655.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_82615.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80303.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40932.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83514.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80747.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_62527.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17265.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39036.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_3274.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_74748.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47190.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17257.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_19446.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_61165.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_64077.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30553.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_68921.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_5646.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_60642.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_36129.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12151.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_85203.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_2401.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57395.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_7520.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_34223.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73254.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_29937.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_53189.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57626.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17088.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_85522.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_10051.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_60592.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_61216.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52607.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_16497.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_61696.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30825.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56443.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_41373.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30624.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50922.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_45740.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40007.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_38601.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_14580.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12449.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73826.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76517.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_5743.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_72409.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12393.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76781.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_21147.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_60464.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_48429.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75545.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79374.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22950.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28460.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_1501.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75414.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47708.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75025.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_2776.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50229.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78242.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80446.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_36480.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_25227.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59104.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43552.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59534.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_6074.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_82598.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50705.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_82131.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_701.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51005.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_44033.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47742.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_38330.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51068.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51646.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12297.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43955.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79488.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_14570.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57737.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42070.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22758.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73115.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40474.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50235.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80672.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_65718.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_1373.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_72337.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_37223.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_34940.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28323.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39662.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_20765.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83581.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30493.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_67971.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54084.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39271.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57669.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_36436.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50812.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_18509.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_72653.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_20074.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_77002.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83359.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42233.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47820.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17059.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_32344.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47605.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_29726.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_64150.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_81031.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30076.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_16565.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33939.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78196.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_66887.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_35456.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_46235.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_8974.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75528.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_5687.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47633.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52186.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56763.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51806.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_3004.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_48993.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_69506.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_26813.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28366.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12261.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_70634.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50201.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33749.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_35385.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_23557.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_25809.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54418.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_62639.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47189.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_14772.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40011.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43589.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_6249.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56941.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_71561.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12200.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78419.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_74704.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_26729.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_77839.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43951.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_46560.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_66549.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12406.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_1562.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_84892.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_64069.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54793.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83455.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79572.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76334.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_gender_from_labels(labels):\n",
        "    if labels is None:\n",
        "        return \"Unclear\"\n",
        "\n",
        "    labels = [label.lower() for label in labels]\n",
        "\n",
        "    if \"man\" in labels or \"male\" in labels:\n",
        "        return \"Male\"\n",
        "    elif \"woman\" in labels or \"female\" in labels:\n",
        "        return \"Female\"\n",
        "    else:\n",
        "        return \"Unclear\"\n"
      ],
      "metadata": {
        "id": "5jVUyRp2TNd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "\n",
        "# Function to get labels from Google Vision API\n",
        "def get_labels_from_vision(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.label_detection(image=image)\n",
        "\n",
        "        labels = [label.description.lower() for label in response.label_annotations]\n",
        "        return labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {image_path}: {e}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "_QYCsUIlUt06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the face detection results if not already available\n",
        "face_results = pd.read_csv(\"face_detection_results.csv\")\n",
        "\n",
        "# Filter only the rows with 'Face detected'\n",
        "face_detected_df = face_results[face_results[\"FaceDetected\"] == \"Face detected\"]\n",
        "\n",
        "# Confirm\n",
        "print(f\"✅ Total images with detected faces: {len(face_detected_df)}\")\n",
        "face_detected_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "6dHb6mktUhGe",
        "outputId": "09051660-bc47-4927-b495-cd8b3ea51b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total images with detected faces: 228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Image   FaceDetected\n",
              "0  image_24520.jpg  Face detected\n",
              "1  image_79300.jpg  Face detected\n",
              "2  image_27678.jpg  Face detected\n",
              "3  image_13904.jpg  Face detected\n",
              "4  image_28227.jpg  Face detected"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6acd87e-bed3-46df-9d08-b2fa3e0cd46e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>FaceDetected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image_24520.jpg</td>\n",
              "      <td>Face detected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image_79300.jpg</td>\n",
              "      <td>Face detected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image_27678.jpg</td>\n",
              "      <td>Face detected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image_13904.jpg</td>\n",
              "      <td>Face detected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image_28227.jpg</td>\n",
              "      <td>Face detected</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6acd87e-bed3-46df-9d08-b2fa3e0cd46e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6acd87e-bed3-46df-9d08-b2fa3e0cd46e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6acd87e-bed3-46df-9d08-b2fa3e0cd46e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0206df5-bd39-4b63-8bd9-ed645593b62f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0206df5-bd39-4b63-8bd9-ed645593b62f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0206df5-bd39-4b63-8bd9-ed645593b62f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "face_detected_df",
              "summary": "{\n  \"name\": \"face_detected_df\",\n  \"rows\": 228,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 228,\n        \"samples\": [\n          \"image_26729.jpg\",\n          \"image_64077.jpg\",\n          \"image_63979.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FaceDetected\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Face detected\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply gender classification to each image in the detected faces list\n",
        "gender_results = []\n",
        "\n",
        "for row in face_detected_df.itertuples(index=False):\n",
        "    image_path = os.path.join(image_dir, row.Image)\n",
        "    print(f\"🔄 Classifying gender in: {image_path}\")\n",
        "\n",
        "    labels = get_labels_from_vision(image_path)\n",
        "    gender = classify_gender_from_labels(labels)\n",
        "\n",
        "    gender_results.append({\n",
        "        \"Image\": row.Image,\n",
        "        \"GenderPrediction\": gender,\n",
        "        \"Labels\": labels\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "gender_df = pd.DataFrame(gender_results)\n",
        "print(\"✅ Gender classification complete!\")\n",
        "gender_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VbYIdTrQSi5s",
        "outputId": "35e1d5a7-2df4-44e3-847d-aca0d64ec247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Classifying gender in: fairface_extracted/image_24520.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79300.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_27678.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_13904.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28227.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76575.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_66016.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39785.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59144.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_63979.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22999.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47111.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_65637.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59803.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_74567.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_38872.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52206.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_21507.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_48764.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_31156.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_21046.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54302.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_26537.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22980.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_15733.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_15653.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_45746.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_25665.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_8336.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_85084.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_70417.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56071.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33837.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43700.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42816.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78667.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_7867.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_63644.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47304.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17609.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73370.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_3792.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_65739.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54865.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52112.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_18407.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_20788.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73072.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50652.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42786.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33592.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_81655.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_82615.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80303.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40932.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83514.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80747.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_62527.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17265.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39036.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_3274.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_74748.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47190.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17257.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_19446.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_61165.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_64077.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30553.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_68921.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_5646.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_60642.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_36129.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12151.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_85203.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_2401.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57395.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_7520.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_34223.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73254.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_29937.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_53189.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57626.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17088.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_85522.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_10051.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_60592.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_61216.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52607.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_16497.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_61696.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30825.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56443.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_41373.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30624.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50922.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_45740.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40007.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_38601.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_14580.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12449.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73826.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76517.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_5743.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_72409.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12393.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76781.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_21147.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_60464.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_48429.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75545.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79374.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22950.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28460.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_1501.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75414.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47708.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75025.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_2776.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50229.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78242.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80446.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_36480.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_25227.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59104.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43552.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_59534.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_6074.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_82598.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50705.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_82131.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_701.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51005.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_44033.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47742.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_38330.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51068.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51646.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12297.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43955.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79488.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_14570.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57737.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42070.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_22758.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_73115.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40474.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50235.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_80672.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_65718.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_1373.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_72337.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_37223.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_34940.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28323.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39662.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_20765.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83581.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30493.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_67971.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54084.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_39271.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_57669.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_36436.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50812.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_18509.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_72653.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_20074.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_77002.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83359.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_42233.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47820.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_17059.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_32344.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47605.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_29726.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_64150.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_81031.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_30076.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_16565.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33939.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78196.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_66887.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_35456.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_46235.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_8974.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_75528.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_5687.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47633.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_52186.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56763.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_51806.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_3004.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_48993.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_69506.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_26813.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_28366.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12261.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_70634.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_50201.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_33749.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_35385.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_23557.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_25809.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54418.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_62639.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_47189.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_14772.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_40011.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43589.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_6249.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_56941.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_71561.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12200.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_78419.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_74704.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_26729.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_77839.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_43951.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_46560.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_66549.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_12406.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_1562.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_84892.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_64069.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_54793.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_83455.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_79572.jpg\n",
            "🔄 Classifying gender in: fairface_extracted/image_76334.jpg\n",
            "✅ Gender classification complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Image GenderPrediction  \\\n",
              "0  image_24520.jpg          Unclear   \n",
              "1  image_79300.jpg          Unclear   \n",
              "2  image_27678.jpg          Unclear   \n",
              "3  image_13904.jpg          Unclear   \n",
              "4  image_28227.jpg          Unclear   \n",
              "\n",
              "                                              Labels  \n",
              "0  [eyewear, glasses, vision care, finger, headge...  \n",
              "1  [chin, cheek, eyebrow, lips, forehead, skin, e...  \n",
              "2  [smile, chin, cheek, happiness, eyebrow, foreh...  \n",
              "3  [smile, chin, cheek, eyebrow, happiness, lips,...  \n",
              "4  [chin, cheek, eyebrow, forehead, lips, skin, j...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de9203f9-c00b-4ee8-974e-e1d7a79a7cf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>GenderPrediction</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image_24520.jpg</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>[eyewear, glasses, vision care, finger, headge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image_79300.jpg</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>[chin, cheek, eyebrow, lips, forehead, skin, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image_27678.jpg</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>[smile, chin, cheek, happiness, eyebrow, foreh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image_13904.jpg</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>[smile, chin, cheek, eyebrow, happiness, lips,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image_28227.jpg</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>[chin, cheek, eyebrow, forehead, lips, skin, j...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de9203f9-c00b-4ee8-974e-e1d7a79a7cf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de9203f9-c00b-4ee8-974e-e1d7a79a7cf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de9203f9-c00b-4ee8-974e-e1d7a79a7cf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aaefe0c9-4b40-474f-9162-b0f0d965fb34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aaefe0c9-4b40-474f-9162-b0f0d965fb34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aaefe0c9-4b40-474f-9162-b0f0d965fb34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "gender_df",
              "summary": "{\n  \"name\": \"gender_df\",\n  \"rows\": 228,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 228,\n        \"samples\": [\n          \"image_26729.jpg\",\n          \"image_64077.jpg\",\n          \"image_63979.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GenderPrediction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unclear\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load face detection results from CSV\n",
        "df_results = pd.read_csv(\"face_detection_results.csv\")\n",
        "\n",
        "# Recreate the dictionary\n",
        "all_results = dict(zip(df_results[\"Image\"], df_results[\"FaceDetected\"]))\n",
        "\n",
        "# Filter only images where a face was detected\n",
        "face_detected_df = df_results[df_results[\"FaceDetected\"] == \"Face detected\"].reset_index(drop=True)\n",
        "\n",
        "# Confirm\n",
        "print(\"✅ Total images with detected faces:\", len(face_detected_df))\n",
        "print(face_detected_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht6rbD7mLuwz",
        "outputId": "864df8f6-3a09-4e2e-9fa2-1e99e5e9f9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total images with detected faces: 228\n",
            "             Image   FaceDetected\n",
            "0  image_24520.jpg  Face detected\n",
            "1  image_79300.jpg  Face detected\n",
            "2  image_27678.jpg  Face detected\n",
            "3  image_13904.jpg  Face detected\n",
            "4  image_28227.jpg  Face detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(list(all_results.items()), columns=[\"Image\", \"FaceDetected\"])\n",
        "\n",
        "# Filter only images where a face was detected\n",
        "face_detected_df = df_results[df_results[\"FaceDetected\"] == \"Face detected\"].reset_index(drop=True)\n",
        "\n",
        "# Confirm\n",
        "print(\"✅ Total images with detected faces:\", len(face_detected_df))\n",
        "print(face_detected_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMTU3N4SLg1t",
        "outputId": "5f69bdf1-9d0a-437c-ee1f-918c9d8d8ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total images with detected faces: 228\n",
            "             Image   FaceDetected\n",
            "0  image_24520.jpg  Face detected\n",
            "1  image_79300.jpg  Face detected\n",
            "2  image_27678.jpg  Face detected\n",
            "3  image_13904.jpg  Face detected\n",
            "4  image_28227.jpg  Face detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gender_results = {}  # Dictionary to store predictions\n",
        "\n",
        "for image_file in face_detected_df[\"Image\"]:\n",
        "    image_path = os.path.join(\"fairface_extracted\", image_file)\n",
        "    print(f\"🔄 Classifying gender in: {image_path}\")\n",
        "\n",
        "    labels = get_labels_from_vision(image_path)\n",
        "    print(f\"🔍 Labels for {image_path}:\", labels)\n",
        "\n",
        "    prediction = classify_gender_from_labels(labels)\n",
        "    gender_results[image_file] = prediction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAMKWEzNLVzo",
        "outputId": "586f11ee-7c65-4928-f2b6-ec3424a4992f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Classifying gender in: fairface_extracted/image_24520.jpg\n",
            "🔍 Labels for fairface_extracted/image_24520.jpg: ['eyewear', 'glasses', 'vision care', 'finger', 'headgear', 'thumb', 'child', 'gesture', 'nail', 'cricket cap']\n",
            "🔄 Classifying gender in: fairface_extracted/image_79300.jpg\n",
            "🔍 Labels for fairface_extracted/image_79300.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'jaw', 'temple', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_27678.jpg\n",
            "🔍 Labels for fairface_extracted/image_27678.jpg: ['smile', 'chin', 'cheek', 'happiness', 'eyebrow', 'forehead', 'skin', 'hairstyle', 'black hair', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_13904.jpg\n",
            "🔍 Labels for fairface_extracted/image_13904.jpg: ['smile', 'chin', 'cheek', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'jaw', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_28227.jpg\n",
            "🔍 Labels for fairface_extracted/image_28227.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'lips', 'skin', 'jaw', 'black hair', 'temple', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_76575.jpg\n",
            "🔍 Labels for fairface_extracted/image_76575.jpg: ['happiness', 'eyebrow', 'lips', 'forehead', 'smile', 'close-up', 'facial expression', 'eyelash', 'tooth', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_66016.jpg\n",
            "🔍 Labels for fairface_extracted/image_66016.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'eyelash', 'beauty', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_39785.jpg\n",
            "🔍 Labels for fairface_extracted/image_39785.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'black hair', 'skin', 'smile', 'happiness', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_59144.jpg\n",
            "🔍 Labels for fairface_extracted/image_59144.jpg: ['chin', 'cheek', 'lips', 'forehead', 'temple', 'neck', 'facial expression', 'headgear', 'wrinkle', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_63979.jpg\n",
            "🔍 Labels for fairface_extracted/image_63979.jpg: ['lips', 'hairstyle', 'black hair', 'beauty', 'bangs', 'jewellery', 'necklace', 'happiness', 'throat', 'flesh']\n",
            "🔄 Classifying gender in: fairface_extracted/image_22999.jpg\n",
            "🔍 Labels for fairface_extracted/image_22999.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw', 'happiness', 'child']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47111.jpg\n",
            "🔍 Labels for fairface_extracted/image_47111.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'neck', 'headgear', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_65637.jpg\n",
            "🔍 Labels for fairface_extracted/image_65637.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'lips', 'skin', 'jaw', 'neck', 'facial expression', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_59803.jpg\n",
            "🔍 Labels for fairface_extracted/image_59803.jpg: ['eyewear', 'smile', 'glasses', 'cheek', 'vision care', 'happiness', 'eyebrow', 'head', 'lips', 'forehead']\n",
            "🔄 Classifying gender in: fairface_extracted/image_74567.jpg\n",
            "🔍 Labels for fairface_extracted/image_74567.jpg: ['eyewear', 'chin', 'glasses', 'cheek', 'eyebrow', 'vision care', 'lips', 'forehead', 'black hair', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_38872.jpg\n",
            "🔍 Labels for fairface_extracted/image_38872.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'black hair', 'jaw', 'hairstyle', 'happiness']\n",
            "🔄 Classifying gender in: fairface_extracted/image_52206.jpg\n",
            "🔍 Labels for fairface_extracted/image_52206.jpg: ['chin', 'smile', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'hairstyle', 'black hair', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_21507.jpg\n",
            "🔍 Labels for fairface_extracted/image_21507.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'neck', 'jaw', 'facial expression', 'black hair', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_48764.jpg\n",
            "🔍 Labels for fairface_extracted/image_48764.jpg: ['chin', 'cheek', 'head', 'forehead', 'wrinkle', 'skin', 'nose', 'face', 'facial hair', 'temple']\n",
            "🔄 Classifying gender in: fairface_extracted/image_31156.jpg\n",
            "🔍 Labels for fairface_extracted/image_31156.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'jaw', 'hairstyle', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_21046.jpg\n",
            "🔍 Labels for fairface_extracted/image_21046.jpg: ['chin', 'facial hair', 'cheek', 'eyebrow', 'lips', 'forehead', 'beard', 'face', 'nose', 'moustache']\n",
            "🔄 Classifying gender in: fairface_extracted/image_54302.jpg\n",
            "🔍 Labels for fairface_extracted/image_54302.jpg: ['chin', 'eyebrow', 'lips', 'forehead', 'happiness', 'skin', 'jaw', 'hairstyle', 'smile', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_26537.jpg\n",
            "🔍 Labels for fairface_extracted/image_26537.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw', 'black hair', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_22980.jpg\n",
            "🔍 Labels for fairface_extracted/image_22980.jpg: ['smile', 'chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'eyelash', 'skin', 'happiness', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_15733.jpg\n",
            "🔍 Labels for fairface_extracted/image_15733.jpg: ['jaw', 'portrait', 'no expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_15653.jpg\n",
            "🔍 Labels for fairface_extracted/image_15653.jpg: ['people', 'chin', 'cheek', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'smile', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_45746.jpg\n",
            "🔍 Labels for fairface_extracted/image_45746.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'hairstyle', 'black hair', 'facial expression', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_25665.jpg\n",
            "🔍 Labels for fairface_extracted/image_25665.jpg: ['chin', 'cheek', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'smile', 'jaw', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_8336.jpg\n",
            "🔍 Labels for fairface_extracted/image_8336.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'black hair', 'hairstyle', 'jaw', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_85084.jpg\n",
            "🔍 Labels for fairface_extracted/image_85084.jpg: ['facial expression', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_70417.jpg\n",
            "🔍 Labels for fairface_extracted/image_70417.jpg: ['chin', 'happiness', 'headgear', 'facial expression', 'smile', 'tooth', 'pleased', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_56071.jpg\n",
            "🔍 Labels for fairface_extracted/image_56071.jpg: ['lips', 'facial expression', 'tooth', 'crying']\n",
            "🔄 Classifying gender in: fairface_extracted/image_33837.jpg\n",
            "🔍 Labels for fairface_extracted/image_33837.jpg: ['skin', 'headgear', 'veil', 'beauty', 'tradition', 'bridal veil', 'necklace', 'happiness', 'headpiece', 'earring']\n",
            "🔄 Classifying gender in: fairface_extracted/image_43700.jpg\n",
            "🔍 Labels for fairface_extracted/image_43700.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'facial expression', 'eyelash', 'close-up', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_42816.jpg\n",
            "🔍 Labels for fairface_extracted/image_42816.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'headgear', 'facial expression', 'happiness', 'tooth', 'scarf']\n",
            "🔄 Classifying gender in: fairface_extracted/image_78667.jpg\n",
            "🔍 Labels for fairface_extracted/image_78667.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'jaw', 'black hair', 'facial expression', 'eyelash', 'facial hair', 'moustache']\n",
            "🔄 Classifying gender in: fairface_extracted/image_7867.jpg\n",
            "🔍 Labels for fairface_extracted/image_7867.jpg: ['chin', 'eyebrow', 'lips', 'hairstyle', 'jaw', 'eyelash', 'facial expression', 'tooth', 'smile', 'happiness']\n",
            "🔄 Classifying gender in: fairface_extracted/image_63644.jpg\n",
            "🔍 Labels for fairface_extracted/image_63644.jpg: ['chin', 'photograph', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'nose', 'eyelash', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47304.jpg\n",
            "🔍 Labels for fairface_extracted/image_47304.jpg: ['eyewear', 'chin', 'glasses', 'vision care', 'forehead', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_17609.jpg\n",
            "🔍 Labels for fairface_extracted/image_17609.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'neck', 'facial expression', 'headgear']\n",
            "🔄 Classifying gender in: fairface_extracted/image_73370.jpg\n",
            "🔍 Labels for fairface_extracted/image_73370.jpg: ['facial hair', 'eyebrow', 'lips', 'forehead', 'beard', 'jaw', 'moustache', 'facial expression', 'eyelash', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_3792.jpg\n",
            "🔍 Labels for fairface_extracted/image_3792.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'facial hair', 'jaw', 'moustache', 'facial expression', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_65739.jpg\n",
            "🔍 Labels for fairface_extracted/image_65739.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'skin', 'smile', 'jaw', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_54865.jpg\n",
            "🔍 Labels for fairface_extracted/image_54865.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'child', 'facial expression', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_52112.jpg\n",
            "🔍 Labels for fairface_extracted/image_52112.jpg: ['eyebrow', 'lips', 'skin', 'black hair', 'eyelash', 'jaw', 'beauty', 'facial expression', 'close-up', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_18407.jpg\n",
            "🔍 Labels for fairface_extracted/image_18407.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'hairstyle', 'eyelash', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_20788.jpg\n",
            "🔍 Labels for fairface_extracted/image_20788.jpg: ['chin', 'smile', 'cheek', 'happiness', 'eyebrow', 'lips', 'forehead', 'skin', 'black hair', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_73072.jpg\n",
            "🔍 Labels for fairface_extracted/image_73072.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'eyelash', 'facial expression', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50652.jpg\n",
            "🔍 Labels for fairface_extracted/image_50652.jpg: ['eyebrow', 'lips', 'forehead', 'smile', 'skin', 'black hair', 'happiness', 'hairstyle', 'eyelash', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_42786.jpg\n",
            "🔍 Labels for fairface_extracted/image_42786.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'skin', 'wrinkle', 'nose', 'jaw', 'hairstyle', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_33592.jpg\n",
            "🔍 Labels for fairface_extracted/image_33592.jpg: ['eyebrow', 'lips', 'forehead', 'jaw', 'facial hair', 'facial expression', 'eyelash', 'moustache', 'beard', 'fun']\n",
            "🔄 Classifying gender in: fairface_extracted/image_81655.jpg\n",
            "🔍 Labels for fairface_extracted/image_81655.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'audio equipment', 'jaw', 'beauty', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_82615.jpg\n",
            "🔍 Labels for fairface_extracted/image_82615.jpg: ['eyebrow', 'forehead', 'happiness', 'facial expression', 'smile', 'tooth', 'facial hair', 'eyelash', 'beard', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_80303.jpg\n",
            "🔍 Labels for fairface_extracted/image_80303.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'red', 'happiness', 'jaw', 'eyelash', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_40932.jpg\n",
            "🔍 Labels for fairface_extracted/image_40932.jpg: ['lips', 'happiness', 'headgear', 'facial expression', 'smile', 'pleased', 'turban']\n",
            "🔄 Classifying gender in: fairface_extracted/image_83514.jpg\n",
            "🔍 Labels for fairface_extracted/image_83514.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'jaw', 'hairstyle', 'neck', 'eyelash', 'facial expression', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_80747.jpg\n",
            "🔍 Labels for fairface_extracted/image_80747.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'black hair', 'eyelash', 'jaw', 'facial expression', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_62527.jpg\n",
            "🔍 Labels for fairface_extracted/image_62527.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'eyelash', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_17265.jpg\n",
            "🔍 Labels for fairface_extracted/image_17265.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'eyelash', 'hairstyle', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_39036.jpg\n",
            "🔍 Labels for fairface_extracted/image_39036.jpg: ['cheek', 'lips', 'forehead', 'skin', 'temple', 'happiness', 'headgear', 'facial expression', 'close-up', 'child']\n",
            "🔄 Classifying gender in: fairface_extracted/image_3274.jpg\n",
            "🔍 Labels for fairface_extracted/image_3274.jpg: ['facial hair', 'chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'beard', 'jaw', 'moustache']\n",
            "🔄 Classifying gender in: fairface_extracted/image_74748.jpg\n",
            "🔍 Labels for fairface_extracted/image_74748.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'black hair', 'temple', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47190.jpg\n",
            "🔍 Labels for fairface_extracted/image_47190.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'black hair', 'jaw', 'facial expression', 'eyelash', 'smile']\n",
            "🔄 Classifying gender in: fairface_extracted/image_17257.jpg\n",
            "🔍 Labels for fairface_extracted/image_17257.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'black hair', 'jaw', 'eyelash', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_19446.jpg\n",
            "🔍 Labels for fairface_extracted/image_19446.jpg: ['eyewear', 'chin', 'glasses', 'cheek', 'eyebrow', 'vision care', 'forehead', 'facial hair', 'face', 'nose']\n",
            "🔄 Classifying gender in: fairface_extracted/image_61165.jpg\n",
            "🔍 Labels for fairface_extracted/image_61165.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'eyelash', 'facial expression', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_64077.jpg\n",
            "🔍 Labels for fairface_extracted/image_64077.jpg: ['eyewear', 'chin', 'glasses', 'cheek', 'eyebrow', 'vision care', 'lips', 'forehead', 'happiness', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_30553.jpg\n",
            "🔍 Labels for fairface_extracted/image_30553.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw', 'neck', 'bangs']\n",
            "🔄 Classifying gender in: fairface_extracted/image_68921.jpg\n",
            "🔍 Labels for fairface_extracted/image_68921.jpg: ['photograph', 'cheek', 'happiness', 'lips', 'smile', 'skin', 'forehead', 'white', 'child', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_5646.jpg\n",
            "🔍 Labels for fairface_extracted/image_5646.jpg: ['lips', 'white', 'facial expression', 'black hair', 'eyelash', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_60642.jpg\n",
            "🔍 Labels for fairface_extracted/image_60642.jpg: ['eyebrow', 'facial hair', 'beard', 'jaw', 'facial expression', 'moustache', 'happiness', 'portrait photography']\n",
            "🔄 Classifying gender in: fairface_extracted/image_36129.jpg\n",
            "🔍 Labels for fairface_extracted/image_36129.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'hairstyle', 'jaw', 'black hair', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12151.jpg\n",
            "🔍 Labels for fairface_extracted/image_12151.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'smile', 'forehead', 'happiness', 'skin', 'hairstyle', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_85203.jpg\n",
            "🔍 Labels for fairface_extracted/image_85203.jpg: ['photograph', 'eyebrow', 'lips', 'forehead', 'white', 'monochrome photography', 'beauty', 'jaw', 'eyelash', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_2401.jpg\n",
            "🔍 Labels for fairface_extracted/image_2401.jpg: ['headgear', 'facial expression', 'cap', 'close-up', 'cricket cap', 'happiness', 'baseball cap', 'visor', 'pleased', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_57395.jpg\n",
            "🔍 Labels for fairface_extracted/image_57395.jpg: ['eyebrow', 'lips', 'happiness', 'black hair', 'hairstyle', 'beauty', 'smile', 'facial expression', 'eyelash', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_7520.jpg\n",
            "🔍 Labels for fairface_extracted/image_7520.jpg: ['eyewear', 'personal protective equipment', 'helmet', 'vision care', 'headgear', 'goggles', 'military person', 'soldier', 'military', 'marines']\n",
            "🔄 Classifying gender in: fairface_extracted/image_34223.jpg\n",
            "🔍 Labels for fairface_extracted/image_34223.jpg: ['facial hair', 'beard', 'moustache', 'temple', 'headgear', 'turban', 'wrinkle', 'guru', 'portrait photography', 'flesh']\n",
            "🔄 Classifying gender in: fairface_extracted/image_73254.jpg\n",
            "🔍 Labels for fairface_extracted/image_73254.jpg: ['chin', 'cheek', 'eyebrow', 'happiness', 'lips', 'smile', 'forehead', 'skin', 'hairstyle', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_29937.jpg\n",
            "🔍 Labels for fairface_extracted/image_29937.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'happiness', 'jaw', 'neck', 'facial expression', 'tooth', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_53189.jpg\n",
            "🔍 Labels for fairface_extracted/image_53189.jpg: ['cheek', 'happiness', 'eyebrow', 'lips', 'skin', 'forehead', 'smile', 'hairstyle', 'black hair', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_57626.jpg\n",
            "🔍 Labels for fairface_extracted/image_57626.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'skin', 'smile', 'happiness', 'jaw', 'hairstyle', 'collar']\n",
            "🔄 Classifying gender in: fairface_extracted/image_17088.jpg\n",
            "🔍 Labels for fairface_extracted/image_17088.jpg: ['eyebrow', 'lips', 'hairstyle', 'jaw', 'happiness', 'facial expression', 'eyelash', 'tooth', 'smile', 'brown hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_85522.jpg\n",
            "🔍 Labels for fairface_extracted/image_85522.jpg: ['lips', 'forehead', 'happiness', 'facial expression', 'gesture', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_10051.jpg\n",
            "🔍 Labels for fairface_extracted/image_10051.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'black hair', 'eyelash', 'jaw', 'facial expression', 'close-up', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_60592.jpg\n",
            "🔍 Labels for fairface_extracted/image_60592.jpg: ['hair', 'smile', 'chin', 'head', 'cheek', 'eyebrow', 'forehead', 'lips', 'skin', 'face']\n",
            "🔄 Classifying gender in: fairface_extracted/image_61216.jpg\n",
            "🔍 Labels for fairface_extracted/image_61216.jpg: ['lips', 'facial expression', 'happiness', 'eyelash', 'close-up', 'gesture', 'pleased']\n",
            "🔄 Classifying gender in: fairface_extracted/image_52607.jpg\n",
            "🔍 Labels for fairface_extracted/image_52607.jpg: ['eyewear', 'glasses', 'cheek', 'eyebrow', 'vision care', 'forehead', 'jaw', 'facial expression', 'monochrome photography', 'facial hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_16497.jpg\n",
            "🔍 Labels for fairface_extracted/image_16497.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'black hair', 'jaw', 'hairstyle', 'temple']\n",
            "🔄 Classifying gender in: fairface_extracted/image_61696.jpg\n",
            "🔍 Labels for fairface_extracted/image_61696.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'eyelash', 'facial expression', 'close-up', 'gesture', 'flesh']\n",
            "🔄 Classifying gender in: fairface_extracted/image_30825.jpg\n",
            "🔍 Labels for fairface_extracted/image_30825.jpg: ['cheek', 'lips', 'skin', 'neck', 'headgear', 'facial expression', 'close-up', 'eyelash', 'flesh', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_56443.jpg\n",
            "🔍 Labels for fairface_extracted/image_56443.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'skin', 'happiness', 'facial expression', 'tooth', 'wrinkle', 'smile']\n",
            "🔄 Classifying gender in: fairface_extracted/image_41373.jpg\n",
            "🔍 Labels for fairface_extracted/image_41373.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'skin', 'nose', 'baby & toddler clothing', 'child', 'eyelash', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_30624.jpg\n",
            "🔍 Labels for fairface_extracted/image_30624.jpg: ['cheek', 'lips', 'forehead', 'skin', 'facial expression', 'close-up', 'happiness', 'child', 'eyelash', 'portrait photography']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50922.jpg\n",
            "🔍 Labels for fairface_extracted/image_50922.jpg: ['eyebrow', 'lips', 'forehead', 'red', 'facial expression', 'orange', 'close-up', 'eyelash', 'gesture', 'happiness']\n",
            "🔄 Classifying gender in: fairface_extracted/image_45740.jpg\n",
            "🔍 Labels for fairface_extracted/image_45740.jpg: ['eyebrow', 'forehead', 'jaw', 'facial expression', 'eyelash', 'close-up', 'child', 'no expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_40007.jpg\n",
            "🔍 Labels for fairface_extracted/image_40007.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'skin', 'child', 'smile', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_38601.jpg\n",
            "🔍 Labels for fairface_extracted/image_38601.jpg: ['lips', 'hairstyle', 'black hair', 'facial expression', 'smile', 'bangs', 'gesture', 'black and white', 'happiness', 'pleased']\n",
            "🔄 Classifying gender in: fairface_extracted/image_14580.jpg\n",
            "🔍 Labels for fairface_extracted/image_14580.jpg: ['facial hair', 'eye', 'moustache', 'facial expression', 'smile', 'tooth', 'happiness', 'beard', 'pleased', 'laughter']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12449.jpg\n",
            "🔍 Labels for fairface_extracted/image_12449.jpg: ['chin', 'cheek', 'smile', 'happiness', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_73826.jpg\n",
            "🔍 Labels for fairface_extracted/image_73826.jpg: ['hair', 'chin', 'cheek', 'eyebrow', 'head', 'lips', 'forehead', 'skin', 'black hair', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_76517.jpg\n",
            "🔍 Labels for fairface_extracted/image_76517.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'facial expression', 'eyelash', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_5743.jpg\n",
            "🔍 Labels for fairface_extracted/image_5743.jpg: ['eyewear', 'sunglasses', 'glasses', 'vision care', 'lips', 'forehead', 'goggles', 'personal protective equipment', 'moustache', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_72409.jpg\n",
            "🔍 Labels for fairface_extracted/image_72409.jpg: ['chin', 'cheek', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'smile', 'black hair', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12393.jpg\n",
            "🔍 Labels for fairface_extracted/image_12393.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'happiness', 'skin', 'facial expression', 'tooth', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_76781.jpg\n",
            "🔍 Labels for fairface_extracted/image_76781.jpg: ['eyewear', 'facial hair', 'chin', 'cheek', 'glasses', 'eyebrow', 'lips', 'vision care', 'happiness', 'forehead']\n",
            "🔄 Classifying gender in: fairface_extracted/image_21147.jpg\n",
            "🔍 Labels for fairface_extracted/image_21147.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'happiness', 'forehead', 'smile', 'jaw', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_60464.jpg\n",
            "🔍 Labels for fairface_extracted/image_60464.jpg: ['eyewear', 'glasses', 'sunglasses', 'vision care', 'head', 'face', 'nose', 'personal protective equipment', 'goggles', 'mouth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_48429.jpg\n",
            "🔍 Labels for fairface_extracted/image_48429.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'jaw', 'neck', 'temple']\n",
            "🔄 Classifying gender in: fairface_extracted/image_75545.jpg\n",
            "🔍 Labels for fairface_extracted/image_75545.jpg: ['eyewear', 'sunglasses', 'glasses', 'vision care', 'lips', 'hairstyle', 'personal protective equipment', 'goggles', 'facial expression', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_79374.jpg\n",
            "🔍 Labels for fairface_extracted/image_79374.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'collar', 'jaw', 'facial hair', 'facial expression', 'smile', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_22950.jpg\n",
            "🔍 Labels for fairface_extracted/image_22950.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'hairstyle', 'black hair', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_28460.jpg\n",
            "🔍 Labels for fairface_extracted/image_28460.jpg: ['eyebrow', 'lips', 'forehead', 'happiness', 'hairstyle', 'black hair', 'beauty', 'facial expression', 'eyelash', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_1501.jpg\n",
            "🔍 Labels for fairface_extracted/image_1501.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'skin', 'jaw', 'headgear', 'neck', 'facial expression', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_75414.jpg\n",
            "🔍 Labels for fairface_extracted/image_75414.jpg: ['smile', 'chin', 'cheek', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47708.jpg\n",
            "🔍 Labels for fairface_extracted/image_47708.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'eyelash', 'facial expression', 'black hair', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_75025.jpg\n",
            "🔍 Labels for fairface_extracted/image_75025.jpg: ['eyebrow', 'lips', 'forehead', 'black hair', 'jaw', 'happiness', 'facial expression', 'close-up', 'tooth', 'child']\n",
            "🔄 Classifying gender in: fairface_extracted/image_2776.jpg\n",
            "🔍 Labels for fairface_extracted/image_2776.jpg: ['chin', 'cheek', 'head', 'happiness', 'eyebrow', 'face', 'smile', 'nose', 'jaw', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50229.jpg\n",
            "🔍 Labels for fairface_extracted/image_50229.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'hairstyle', 'jaw', 'eyelash', 'facial expression', 'black hair', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_78242.jpg\n",
            "🔍 Labels for fairface_extracted/image_78242.jpg: ['facial hair', 'cheek', 'eyebrow', 'lips', 'beard', 'moustache', 'jaw', 'headgear', 'monochrome photography', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_80446.jpg\n",
            "🔍 Labels for fairface_extracted/image_80446.jpg: ['eyebrow', 'headgear', 'facial expression', 'hat', 'child', 'eyelash', 'cap', 'portrait photography', 'sun hat', 'toddler']\n",
            "🔄 Classifying gender in: fairface_extracted/image_36480.jpg\n",
            "🔍 Labels for fairface_extracted/image_36480.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'nose', 'eyelash', 'hairstyle', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_25227.jpg\n",
            "🔍 Labels for fairface_extracted/image_25227.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'facial expression', 'eyelash', 'black hair', 'close-up', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_59104.jpg\n",
            "🔍 Labels for fairface_extracted/image_59104.jpg: ['smile', 'chin', 'cheek', 'happiness', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_43552.jpg\n",
            "🔍 Labels for fairface_extracted/image_43552.jpg: ['cheek', 'eyebrow', 'lips', 'headgear', 'facial expression', 'eyelash', 'close-up', 'child', 'hat', 'sun hat']\n",
            "🔄 Classifying gender in: fairface_extracted/image_59534.jpg\n",
            "🔍 Labels for fairface_extracted/image_59534.jpg: ['eyebrow', 'forehead', 'skin', 'jaw', 'facial expression', 'eyelash', 'fun', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_6074.jpg\n",
            "🔍 Labels for fairface_extracted/image_6074.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'black hair', 'child', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_82598.jpg\n",
            "🔍 Labels for fairface_extracted/image_82598.jpg: ['photograph', 'eyebrow', 'lips', 'forehead', 'white', 'jaw', 'monochrome photography', 'neck', 'facial expression', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50705.jpg\n",
            "🔍 Labels for fairface_extracted/image_50705.jpg: ['chin', 'cheek', 'eyebrow', 'happiness', 'forehead', 'skin', 'smile', 'jaw', 'neck', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_82131.jpg\n",
            "🔍 Labels for fairface_extracted/image_82131.jpg: ['lips', 'temple', 'black hair', 'facial expression', 'eyelash', 'happiness', 'earring', 'portrait photography', 'body piercing', 'pleased']\n",
            "🔄 Classifying gender in: fairface_extracted/image_701.jpg\n",
            "🔍 Labels for fairface_extracted/image_701.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'hairstyle', 'jaw', 'temple', 'black hair', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_51005.jpg\n",
            "🔍 Labels for fairface_extracted/image_51005.jpg: ['eyewear', 'smile', 'chin', 'cheek', 'happiness', 'eyebrow', 'glasses', 'lips', 'forehead', 'vision care']\n",
            "🔄 Classifying gender in: fairface_extracted/image_44033.jpg\n",
            "🔍 Labels for fairface_extracted/image_44033.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'hairstyle', 'happiness', 'black hair', 'facial hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47742.jpg\n",
            "🔍 Labels for fairface_extracted/image_47742.jpg: ['hair', 'eyebrow', 'lips', 'eyelash', 'hairstyle', 'beauty', 'black hair', 'facial expression', 'long hair', 'headpiece']\n",
            "🔄 Classifying gender in: fairface_extracted/image_38330.jpg\n",
            "🔍 Labels for fairface_extracted/image_38330.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'facial expression', 'child', 'eyelash', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_51068.jpg\n",
            "🔍 Labels for fairface_extracted/image_51068.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'facial hair', 'skin', 'eyelash', 'nose', 'jaw', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_51646.jpg\n",
            "🔍 Labels for fairface_extracted/image_51646.jpg: ['smile', 'cheek', 'eyebrow', 'lips', 'happiness', 'forehead', 'skin', 'beauty', 'facial expression', 'headgear']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12297.jpg\n",
            "🔍 Labels for fairface_extracted/image_12297.jpg: ['eyewear', 'chin', 'glasses', 'cheek', 'vision care', 'eyebrow', 'forehead', 'happiness', 'jaw', 'temple']\n",
            "🔄 Classifying gender in: fairface_extracted/image_43955.jpg\n",
            "🔍 Labels for fairface_extracted/image_43955.jpg: ['eyewear', 'glasses', 'eyebrow', 'vision care', 'lips', 'forehead', 'black hair', 'jaw', 'facial expression', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_79488.jpg\n",
            "🔍 Labels for fairface_extracted/image_79488.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'black hair', 'hairstyle', 'jaw', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_14570.jpg\n",
            "🔍 Labels for fairface_extracted/image_14570.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'collar', 'jaw', 'neck', 'facial expression', 'facial hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_57737.jpg\n",
            "🔍 Labels for fairface_extracted/image_57737.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'happiness', 'forehead', 'skin', 'smile', 'hairstyle', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_42070.jpg\n",
            "🔍 Labels for fairface_extracted/image_42070.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'lips', 'happiness', 'skin', 'smile', 'hairstyle', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_22758.jpg\n",
            "🔍 Labels for fairface_extracted/image_22758.jpg: ['cheek', 'eyebrow', 'happiness', 'lips', 'forehead', 'skin', 'black hair', 'hairstyle', 'smile', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_73115.jpg\n",
            "🔍 Labels for fairface_extracted/image_73115.jpg: ['eyewear', 'glasses', 'cheek', 'eyebrow', 'vision care', 'forehead', 'facial hair', 'jaw', 'beard', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_40474.jpg\n",
            "🔍 Labels for fairface_extracted/image_40474.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'black hair', 'jaw', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50235.jpg\n",
            "🔍 Labels for fairface_extracted/image_50235.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'lips', 'skin', 'eyelash', 'hairstyle', 'jaw', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_80672.jpg\n",
            "🔍 Labels for fairface_extracted/image_80672.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'neck', 'black hair', 'facial expression', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_65718.jpg\n",
            "🔍 Labels for fairface_extracted/image_65718.jpg: ['eyewear', 'chin', 'glasses', 'cheek', 'vision care', 'eyebrow', 'forehead', 'face', 'nose', 'facial hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_1373.jpg\n",
            "🔍 Labels for fairface_extracted/image_1373.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'skin', 'facial hair', 'jaw', 'black hair', 'facial expression', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_72337.jpg\n",
            "🔍 Labels for fairface_extracted/image_72337.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'audio equipment', 'eyelash', 'entertainment', 'earring', 'singing', 'headphones']\n",
            "🔄 Classifying gender in: fairface_extracted/image_37223.jpg\n",
            "🔍 Labels for fairface_extracted/image_37223.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'hairstyle', 'eyelash', 'facial expression', 'blond']\n",
            "🔄 Classifying gender in: fairface_extracted/image_34940.jpg\n",
            "🔍 Labels for fairface_extracted/image_34940.jpg: ['cheek', 'lips', 'skin', 'happiness', 'finger', 'facial expression', 'tooth', 'child', 'gesture', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_28323.jpg\n",
            "🔍 Labels for fairface_extracted/image_28323.jpg: ['cheek', 'eyebrow', 'facial expression', 'eyelash', 'child', 'gesture', 'bangs', 'happiness', 'toddler']\n",
            "🔄 Classifying gender in: fairface_extracted/image_39662.jpg\n",
            "🔍 Labels for fairface_extracted/image_39662.jpg: ['eyewear', 'glasses', 'vision care', 'eyebrow', 'lips', 'forehead', 'facial expression', 'eyelash', 'happiness', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_20765.jpg\n",
            "🔍 Labels for fairface_extracted/image_20765.jpg: ['eyewear', 'glasses', 'vision care', 'eyebrow', 'lips', 'sunglasses', 'hairstyle', 'beauty', 'facial expression', 'goggles']\n",
            "🔄 Classifying gender in: fairface_extracted/image_83581.jpg\n",
            "🔍 Labels for fairface_extracted/image_83581.jpg: ['chin', 'photograph', 'cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'white', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_30493.jpg\n",
            "🔍 Labels for fairface_extracted/image_30493.jpg: ['lips', 'headgear', 'facial expression', 'cap', 'hat', 'close-up', 'cricket cap', 'baseball cap', 'flesh', 'visor']\n",
            "🔄 Classifying gender in: fairface_extracted/image_67971.jpg\n",
            "🔍 Labels for fairface_extracted/image_67971.jpg: ['eyewear', 'chin', 'glasses', 'eyebrow', 'vision care', 'forehead', 'skin', 'jaw', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_54084.jpg\n",
            "🔍 Labels for fairface_extracted/image_54084.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'lips', 'skin', 'eyelash', 'nose', 'jaw', 'temple']\n",
            "🔄 Classifying gender in: fairface_extracted/image_39271.jpg\n",
            "🔍 Labels for fairface_extracted/image_39271.jpg: ['eyewear', 'forehead', 'glasses', 'vision care', 'facial expression', 'wrinkle', 'happiness', 'gesture', 'pleased', 'elder']\n",
            "🔄 Classifying gender in: fairface_extracted/image_57669.jpg\n",
            "🔍 Labels for fairface_extracted/image_57669.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'facial expression', 'happiness', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_36436.jpg\n",
            "🔍 Labels for fairface_extracted/image_36436.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'skin', 'happiness', 'black hair', 'jaw', 'hairstyle', 'smile']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50812.jpg\n",
            "🔍 Labels for fairface_extracted/image_50812.jpg: ['finger', 'water gun', 'child', 'happiness', 'fun', 'toy', 'toddler', 'thumb', 'play', 'cap']\n",
            "🔄 Classifying gender in: fairface_extracted/image_18509.jpg\n",
            "🔍 Labels for fairface_extracted/image_18509.jpg: ['eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'smile', 'black hair', 'hairstyle', 'eyelash', 'beauty']\n",
            "🔄 Classifying gender in: fairface_extracted/image_72653.jpg\n",
            "🔍 Labels for fairface_extracted/image_72653.jpg: ['lips', 'headgear', 'facial expression', 'hat', 'cap', 'cricket cap', 'visor', 'baseball cap', 'portrait photography']\n",
            "🔄 Classifying gender in: fairface_extracted/image_20074.jpg\n",
            "🔍 Labels for fairface_extracted/image_20074.jpg: ['eyebrow', 'forehead', 'happiness', 'smile', 'jaw', 'facial expression', 'tooth', 'eyelash', 'brown hair', 'pleased']\n",
            "🔄 Classifying gender in: fairface_extracted/image_77002.jpg\n",
            "🔍 Labels for fairface_extracted/image_77002.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'jaw', 'hairstyle', 'eyelash', 'black hair', 'facial hair', 'beard']\n",
            "🔄 Classifying gender in: fairface_extracted/image_83359.jpg\n",
            "🔍 Labels for fairface_extracted/image_83359.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'smile', 'happiness', 'hairstyle', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_42233.jpg\n",
            "🔍 Labels for fairface_extracted/image_42233.jpg: ['people', 'chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'hairstyle', 'jaw', 'eyelash', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47820.jpg\n",
            "🔍 Labels for fairface_extracted/image_47820.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'nose', 'eyelash', 'jaw', 'eye']\n",
            "🔄 Classifying gender in: fairface_extracted/image_17059.jpg\n",
            "🔍 Labels for fairface_extracted/image_17059.jpg: ['eyebrow', 'lips', 'forehead', 'happiness', 'black hair', 'jaw', 'facial expression', 'eyelash', 'close-up', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_32344.jpg\n",
            "🔍 Labels for fairface_extracted/image_32344.jpg: ['people', 'happiness', 'eyebrow', 'lips', 'smile', 'forehead', 'skin', 'facial expression', 'tooth', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47605.jpg\n",
            "🔍 Labels for fairface_extracted/image_47605.jpg: ['lips', 'headgear', 'eyelash', 'close-up', 'cap', 'cricket cap']\n",
            "🔄 Classifying gender in: fairface_extracted/image_29726.jpg\n",
            "🔍 Labels for fairface_extracted/image_29726.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'jaw', 'eyelash', 'facial expression', 'black hair', 'close-up', 'portrait photography']\n",
            "🔄 Classifying gender in: fairface_extracted/image_64150.jpg\n",
            "🔍 Labels for fairface_extracted/image_64150.jpg: ['eyewear', 'facial hair', 'smile', 'glasses', 'vision care', 'eyebrow', 'beard', 'happiness', 'forehead', 'moustache']\n",
            "🔄 Classifying gender in: fairface_extracted/image_81031.jpg\n",
            "🔍 Labels for fairface_extracted/image_81031.jpg: ['eyebrow', 'lips', 'jaw', 'facial expression', 'eyelash', 'close-up', 'portrait photography', 'no expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_30076.jpg\n",
            "🔍 Labels for fairface_extracted/image_30076.jpg: ['cheek', 'lips', 'happiness', 'facial expression', 'tooth', 'child', 'eyelash', 'gesture', 'toddler', 'crying']\n",
            "🔄 Classifying gender in: fairface_extracted/image_16565.jpg\n",
            "🔍 Labels for fairface_extracted/image_16565.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'temple', 'black hair', 'neck', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_33939.jpg\n",
            "🔍 Labels for fairface_extracted/image_33939.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'hairstyle', 'jaw', 'black hair', 'eyelash', 'facial expression', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_78196.jpg\n",
            "🔍 Labels for fairface_extracted/image_78196.jpg: ['cheek', 'eyebrow', 'lips', 'skin', 'forehead', 'happiness', 'facial expression', 'close-up', 'tooth', 'child']\n",
            "🔄 Classifying gender in: fairface_extracted/image_66887.jpg\n",
            "🔍 Labels for fairface_extracted/image_66887.jpg: ['eyewear', 'glasses', 'vision care', 'eyebrow', 'lips', 'forehead', 'happiness', 'jaw', 'facial expression', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_35456.jpg\n",
            "🔍 Labels for fairface_extracted/image_35456.jpg: ['camera', 'cameras & optics', 'hand', 'digital camera', 'finger', 'lens', 'reflex camera', 'nail', 'point-and-shoot camera', 'camera lens']\n",
            "🔄 Classifying gender in: fairface_extracted/image_46235.jpg\n",
            "🔍 Labels for fairface_extracted/image_46235.jpg: ['headgear', 'cap', 'eyelash', 'baseball cap', 'cricket cap', 'visor']\n",
            "🔄 Classifying gender in: fairface_extracted/image_8974.jpg\n",
            "🔍 Labels for fairface_extracted/image_8974.jpg: ['cheek', 'lips', 'taste', 'finger', 'eyelash', 'eating', 'food craving', 'nail', 'gesture', 'drinking']\n",
            "🔄 Classifying gender in: fairface_extracted/image_75528.jpg\n",
            "🔍 Labels for fairface_extracted/image_75528.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'close-up', 'facial expression', 'eyelash', 'child']\n",
            "🔄 Classifying gender in: fairface_extracted/image_5687.jpg\n",
            "🔍 Labels for fairface_extracted/image_5687.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'hairstyle', 'black hair', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47633.jpg\n",
            "🔍 Labels for fairface_extracted/image_47633.jpg: ['facial expression', 'headgear', 'thorax', 'barechestedness', 'flesh', 'mud', 'child', 'clay']\n",
            "🔄 Classifying gender in: fairface_extracted/image_52186.jpg\n",
            "🔍 Labels for fairface_extracted/image_52186.jpg: ['eyebrow', 'jaw', 'black hair', 'facial expression', 'happiness', 'pleased', 'selfie', 'portrait photography']\n",
            "🔄 Classifying gender in: fairface_extracted/image_56763.jpg\n",
            "🔍 Labels for fairface_extracted/image_56763.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'jaw', 'neck', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_51806.jpg\n",
            "🔍 Labels for fairface_extracted/image_51806.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'happiness', 'hairstyle', 'jaw', 'smile']\n",
            "🔄 Classifying gender in: fairface_extracted/image_3004.jpg\n",
            "🔍 Labels for fairface_extracted/image_3004.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'hairstyle', 'eyelash', 'black hair', 'jaw', 'ear', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_48993.jpg\n",
            "🔍 Labels for fairface_extracted/image_48993.jpg: ['lips', 'forehead', 'headgear', 'facial expression', 'cap', 'happiness', 'hat', 'facial hair', 'baseball cap', 'selfie']\n",
            "🔄 Classifying gender in: fairface_extracted/image_69506.jpg\n",
            "🔍 Labels for fairface_extracted/image_69506.jpg: ['cheek', 'skin', 'taste', 'eating', 'child', 'eyelash', 'biting', 'close-up', 'food craving', 'toddler']\n",
            "🔄 Classifying gender in: fairface_extracted/image_26813.jpg\n",
            "🔍 Labels for fairface_extracted/image_26813.jpg: ['cheek', 'eyebrow', 'lips', 'forehead', 'eyelash', 'jaw', 'neck', 'facial expression', 'brown hair', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_28366.jpg\n",
            "🔍 Labels for fairface_extracted/image_28366.jpg: ['lips', 'eyelash', 'beauty', 'facial expression', 'earring', 'eye liner', 'body piercing', 'lipstick']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12261.jpg\n",
            "🔍 Labels for fairface_extracted/image_12261.jpg: ['smile', 'happiness', 'headgear', 'facial expression', 'pleased', 'selfie', 'portrait photography']\n",
            "🔄 Classifying gender in: fairface_extracted/image_70634.jpg\n",
            "🔍 Labels for fairface_extracted/image_70634.jpg: ['eyewear', 'chin', 'glasses', 'vision care', 'eyebrow', 'lips', 'forehead', 'happiness', 'jaw', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_50201.jpg\n",
            "🔍 Labels for fairface_extracted/image_50201.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'hairstyle', 'eyelash', 'jaw', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_33749.jpg\n",
            "🔍 Labels for fairface_extracted/image_33749.jpg: ['eyebrow', 'lips', 'forehead', 'black hair', 'jaw', 'facial expression', 'eyelash', 'close-up', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_35385.jpg\n",
            "🔍 Labels for fairface_extracted/image_35385.jpg: ['forehead', 'finger', 'hand', 'facial expression', 'eyelash', 'gesture', 'thumb', 'nail', 'worry', 'child']\n",
            "🔄 Classifying gender in: fairface_extracted/image_23557.jpg\n",
            "🔍 Labels for fairface_extracted/image_23557.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'jaw', 'beauty', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_25809.jpg\n",
            "🔍 Labels for fairface_extracted/image_25809.jpg: ['facial hair', 'chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'beard', 'moustache', 'jaw', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_54418.jpg\n",
            "🔍 Labels for fairface_extracted/image_54418.jpg: ['eyewear', 'glasses', 'eyebrow', 'vision care', 'forehead', 'jaw', 'facial expression', 'collar', 'tooth', 'happiness']\n",
            "🔄 Classifying gender in: fairface_extracted/image_62639.jpg\n",
            "🔍 Labels for fairface_extracted/image_62639.jpg: ['eyebrow', 'lips', 'smile', 'forehead', 'skin', 'happiness', 'beauty', 'facial expression', 'headgear', 'tooth']\n",
            "🔄 Classifying gender in: fairface_extracted/image_47189.jpg\n",
            "🔍 Labels for fairface_extracted/image_47189.jpg: ['eyewear', 'eyebrow', 'lips', 'forehead', 'vision care', 'jaw', 'black hair', 'facial expression', 'close-up']\n",
            "🔄 Classifying gender in: fairface_extracted/image_14772.jpg\n",
            "🔍 Labels for fairface_extracted/image_14772.jpg: ['eyewear', 'sunglasses', 'glasses', 'vision care', 'personal protective equipment', 'goggles', 'happiness', 'summer', 'facial expression', 'smile']\n",
            "🔄 Classifying gender in: fairface_extracted/image_40011.jpg\n",
            "🔍 Labels for fairface_extracted/image_40011.jpg: ['facial expression', 'eyelash', 'happiness', 'pleased', 'flesh']\n",
            "🔄 Classifying gender in: fairface_extracted/image_43589.jpg\n",
            "🔍 Labels for fairface_extracted/image_43589.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'hairstyle', 'eyelash', 'temple']\n",
            "🔄 Classifying gender in: fairface_extracted/image_6249.jpg\n",
            "🔍 Labels for fairface_extracted/image_6249.jpg: ['cheek', 'smile', 'happiness', 'eyebrow', 'forehead', 'lips', 'skin', 'hairstyle', 'jaw', 'black hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_56941.jpg\n",
            "🔍 Labels for fairface_extracted/image_56941.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'black hair', 'temple', 'eyelash']\n",
            "🔄 Classifying gender in: fairface_extracted/image_71561.jpg\n",
            "🔍 Labels for fairface_extracted/image_71561.jpg: ['eyebrow', 'lips', 'forehead', 'black hair', 'jaw', 'facial expression', 'close-up', 'happiness', 'child', 'pleased']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12200.jpg\n",
            "🔍 Labels for fairface_extracted/image_12200.jpg: ['eyewear', 'glasses', 'cheek', 'vision care', 'eyebrow', 'lips', 'forehead', 'jaw', 'black hair', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_78419.jpg\n",
            "🔍 Labels for fairface_extracted/image_78419.jpg: ['eyewear', 'people', 'smile', 'cheek', 'glasses', 'happiness', 'eyebrow', 'vision care', 'lips', 'forehead']\n",
            "🔄 Classifying gender in: fairface_extracted/image_74704.jpg\n",
            "🔍 Labels for fairface_extracted/image_74704.jpg: ['lips', 'facial expression', 'blond']\n",
            "🔄 Classifying gender in: fairface_extracted/image_26729.jpg\n",
            "🔍 Labels for fairface_extracted/image_26729.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'jaw', 'facial expression', 'child', 'happiness']\n",
            "🔄 Classifying gender in: fairface_extracted/image_77839.jpg\n",
            "🔍 Labels for fairface_extracted/image_77839.jpg: ['eyebrow', 'lips', 'forehead', 'jaw', 'facial expression', 'eyelash', 'black hair', 'no expression', 'portrait']\n",
            "🔄 Classifying gender in: fairface_extracted/image_43951.jpg\n",
            "🔍 Labels for fairface_extracted/image_43951.jpg: ['facial expression', 'gesture', 'facial hair', 'moustache', 'worry', 'wrinkle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_46560.jpg\n",
            "🔍 Labels for fairface_extracted/image_46560.jpg: ['chin', 'eyebrow', 'lips', 'smile', 'forehead', 'happiness', 'skin', 'hairstyle', 'beauty', 'jaw']\n",
            "🔄 Classifying gender in: fairface_extracted/image_66549.jpg\n",
            "🔍 Labels for fairface_extracted/image_66549.jpg: ['chin', 'cheek', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'black hair', 'jaw', 'hairstyle']\n",
            "🔄 Classifying gender in: fairface_extracted/image_12406.jpg\n",
            "🔍 Labels for fairface_extracted/image_12406.jpg: ['lips', 'happiness', 'jaw', 'facial expression', 'smile', 'tooth', 'eyelash', 'facial hair', 'moustache', 'gesture']\n",
            "🔄 Classifying gender in: fairface_extracted/image_1562.jpg\n",
            "🔍 Labels for fairface_extracted/image_1562.jpg: ['hair', 'eyebrow', 'lips', 'forehead', 'skin', 'eyelash', 'hairstyle', 'beauty', 'black hair', 'facial expression']\n",
            "🔄 Classifying gender in: fairface_extracted/image_84892.jpg\n",
            "🔍 Labels for fairface_extracted/image_84892.jpg: ['chin', 'photograph', 'cheek', 'lips', 'skin', 'facial expression', 'child', 'eyelash', 'close-up', 'happiness']\n",
            "🔄 Classifying gender in: fairface_extracted/image_64069.jpg\n",
            "🔍 Labels for fairface_extracted/image_64069.jpg: ['lips', 'happiness', 'smile', 'beauty', 'headgear', 'facial expression', 'eyelash', 'tooth', 'brown hair', 'long hair']\n",
            "🔄 Classifying gender in: fairface_extracted/image_54793.jpg\n",
            "🔍 Labels for fairface_extracted/image_54793.jpg: ['lips', 'happiness', 'smile', 'facial expression', 'collar', 'tooth', 'close-up', 'pleased', 'white-collar worker', 'laughter']\n",
            "🔄 Classifying gender in: fairface_extracted/image_83455.jpg\n",
            "🔍 Labels for fairface_extracted/image_83455.jpg: ['eyebrow', 'jaw', 'facial expression', 'black hair', 'happiness', 'smile', 'facial hair', 'selfie', 'moustache', 'pleased']\n",
            "🔄 Classifying gender in: fairface_extracted/image_79572.jpg\n",
            "🔍 Labels for fairface_extracted/image_79572.jpg: ['chin', 'cheek', 'eyebrow', 'forehead', 'lips', 'skin', 'hairstyle', 'jaw', 'temple', 'neck']\n",
            "🔄 Classifying gender in: fairface_extracted/image_76334.jpg\n",
            "🔍 Labels for fairface_extracted/image_76334.jpg: ['lips', 'facial expression', 'close-up', 'gesture']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print(\"✅ Sample gender results:\", list(gender_results.items())[:5])\n",
        "except NameError:\n",
        "    print(\"❌ 'gender_results' is not defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1mpOqi8LLyt",
        "outputId": "aad71c39-255f-4c4e-cd84-02663b4c1678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sample gender results: [('image_24520.jpg', 'Unclear'), ('image_79300.jpg', 'Unclear'), ('image_27678.jpg', 'Unclear'), ('image_13904.jpg', 'Unclear'), ('image_28227.jpg', 'Unclear')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df_gender = pd.DataFrame(list(gender_results.items()), columns=[\"Image\", \"GenderPrediction\"])\n",
        "\n",
        "# Save to CSV\n",
        "df_gender.to_csv(\"gender_classification_results.csv\", index=False)\n",
        "\n",
        "print(\"✅ Gender predictions saved to gender_classification_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAtDkGUeW-aa",
        "outputId": "6feba4e6-7b0a-48d4-d109-15df03cd1415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gender predictions saved to gender_classification_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "import os\n",
        "\n",
        "# Initialize Google Vision client (if not done already)\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# Load the face-detected DataFrame\n",
        "import pandas as pd\n",
        "face_df = pd.read_csv(\"face_detection_results.csv\")\n",
        "face_detected_df = face_df[face_df[\"FaceDetected\"] == \"Face detected\"]\n",
        "\n",
        "# Limit to a smaller sample for now (e.g., 1000) to avoid long processing time\n",
        "face_detected_df = face_detected_df[:1000]\n",
        "\n",
        "# Dictionary to hold labels\n",
        "label_results = {}\n",
        "\n",
        "for img_name in face_detected_df[\"Image\"]:\n",
        "    image_path = os.path.join(\"fairface_extracted\", img_name)\n",
        "    print(f\"🔍 Getting labels for {image_path}...\")\n",
        "\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.label_detection(image=image)\n",
        "        labels = [label.description.lower() for label in response.label_annotations]\n",
        "\n",
        "        label_results[img_name] = labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error with {image_path}: {e}\")\n",
        "        label_results[img_name] = []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmqjFnwGP08C",
        "outputId": "96aeb72d-8913-422e-c3a7-25766f314115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Getting labels for fairface_extracted/image_24520.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_79300.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_27678.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_13904.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_28227.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_76575.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_66016.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_39785.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_59144.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_63979.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_22999.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47111.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_65637.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_59803.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_74567.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_38872.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_52206.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_21507.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_48764.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_31156.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_21046.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_54302.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_26537.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_22980.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_15733.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_15653.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_45746.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_25665.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_8336.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_85084.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_70417.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_56071.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_33837.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_43700.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_42816.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_78667.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_7867.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_63644.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47304.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_17609.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_73370.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_3792.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_65739.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_54865.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_52112.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_18407.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_20788.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_73072.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50652.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_42786.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_33592.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_81655.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_82615.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_80303.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_40932.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_83514.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_80747.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_62527.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_17265.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_39036.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_3274.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_74748.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47190.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_17257.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_19446.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_61165.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_64077.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_30553.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_68921.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_5646.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_60642.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_36129.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12151.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_85203.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_2401.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_57395.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_7520.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_34223.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_73254.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_29937.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_53189.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_57626.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_17088.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_85522.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_10051.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_60592.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_61216.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_52607.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_16497.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_61696.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_30825.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_56443.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_41373.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_30624.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50922.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_45740.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_40007.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_38601.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_14580.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12449.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_73826.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_76517.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_5743.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_72409.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12393.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_76781.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_21147.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_60464.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_48429.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_75545.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_79374.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_22950.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_28460.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_1501.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_75414.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47708.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_75025.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_2776.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50229.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_78242.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_80446.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_36480.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_25227.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_59104.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_43552.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_59534.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_6074.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_82598.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50705.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_82131.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_701.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_51005.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_44033.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47742.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_38330.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_51068.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_51646.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12297.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_43955.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_79488.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_14570.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_57737.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_42070.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_22758.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_73115.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_40474.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50235.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_80672.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_65718.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_1373.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_72337.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_37223.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_34940.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_28323.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_39662.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_20765.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_83581.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_30493.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_67971.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_54084.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_39271.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_57669.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_36436.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50812.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_18509.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_72653.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_20074.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_77002.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_83359.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_42233.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47820.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_17059.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_32344.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47605.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_29726.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_64150.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_81031.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_30076.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_16565.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_33939.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_78196.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_66887.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_35456.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_46235.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_8974.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_75528.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_5687.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47633.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_52186.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_56763.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_51806.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_3004.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_48993.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_69506.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_26813.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_28366.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12261.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_70634.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_50201.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_33749.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_35385.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_23557.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_25809.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_54418.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_62639.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_47189.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_14772.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_40011.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_43589.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_6249.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_56941.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_71561.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12200.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_78419.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_74704.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_26729.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_77839.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_43951.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_46560.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_66549.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_12406.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_1562.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_84892.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_64069.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_54793.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_83455.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_79572.jpg...\n",
            "🔍 Getting labels for fairface_extracted/image_76334.jpg...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Combine all labels into one list\n",
        "all_labels = []\n",
        "for label_list in label_results.values():\n",
        "    all_labels.extend(label_list)\n",
        "\n",
        "# Count occurrences\n",
        "label_counts = Counter(all_labels).most_common(20)\n",
        "\n",
        "# Plot\n",
        "labels, counts = zip(*label_counts)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(labels, counts)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.title(\"Top 20 Labels Detected by Google Vision\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "4npv0GavQ392",
        "outputId": "dc61ab9c-b746-4669-a7d3-8581c3d37525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_gender_from_labels(labels):\n",
        "    labels = [label.lower() for label in labels]\n",
        "    if \"man\" in labels or \"male\" in labels:\n",
        "        return \"Male\"\n",
        "    elif \"woman\" in labels or \"female\" in labels:\n",
        "        return \"Female\"\n",
        "    else:\n",
        "        return \"Unclear\"\n"
      ],
      "metadata": {
        "id": "iy8zDHbiRE8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_results = {}\n",
        "\n",
        "for img_name, labels in label_results.items():\n",
        "    gender = extract_gender_from_labels(labels)\n",
        "    gender_results[img_name] = gender\n"
      ],
      "metadata": {
        "id": "_cciZkirRHm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_gender = pd.DataFrame(list(gender_results.items()), columns=[\"Image\", \"GenderPrediction\"])\n",
        "df_gender.to_csv(\"gender_classification_results.csv\", index=False)\n",
        "\n",
        "print(\"✅ Gender predictions saved to gender_classification_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdFiaLeXRKCL",
        "outputId": "8f1659cf-d6b1-420c-e586-d84f12358b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gender predictions saved to gender_classification_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count gender predictions\n",
        "gender_counts = Counter(gender_results.values())\n",
        "\n",
        "# Plot\n",
        "labels, counts = zip(*gender_counts.items())\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(labels, counts, color=[\"lightblue\", \"pink\", \"gray\"])\n",
        "plt.title(\"Gender Predictions by Google Vision\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fxxSfE7ZRXCl",
        "outputId": "a190ce4e-b286-4d62-df03-071a7d74753e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**## Not used**"
      ],
      "metadata": {
        "id": "qWoNjcmwJ7SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "import os\n",
        "#Initialize Google Vision client\n",
        "\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "#print(\"Google vision API is ready\")\n",
        "image_dir = \"fairface_extracted\"\n",
        "\n",
        "#Function to loop through all the images in the folder\n",
        "def process_all_images(image_dir):\n",
        "\n",
        "  results= {}\n",
        "      # Debugging: Check if directory exists and has images\n",
        "  if not os.path.exists(image_dir):\n",
        "      #print(f\"❌ ERROR: Directory '{image_dir}' does not exist.\")\n",
        "      return {}\n",
        "\n",
        "  if not os.listdir(image_dir):\n",
        "      #print(f\"⚠ WARNING: Directory '{image_dir}' is EMPTY.\")\n",
        "      return {}\n",
        "\n",
        "\n",
        "\n",
        "  #loop through all files in the folder\n",
        "  for image_file in os.listdir(image_dir):\n",
        "    image_path= os.path.join(image_dir, image_file)\n",
        "\n",
        "    if not os.path.isfile(image_path):\n",
        "      continue\n",
        "\n",
        "    #print(f\"Processing: {image_path}\")\n",
        "    result= get_gender_prediction(image_path)\n",
        "\n",
        "    if result is not None:\n",
        "      results[image_file] = result\n",
        "      #print(f\"stored: {image_file} + {result}\")\n",
        "  #print(\"total images processed: {len(results)}\")\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "#Function to send an image and get gender classification\n",
        "def get_gender_prediction(image_path):\n",
        "  #reading image file\n",
        "  try:\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "      content = image_file.read()\n",
        "\n",
        "      #creating a vision API request\n",
        "      image = vision.Image(content= content)\n",
        "      response = client.face_detection(image=image, max_results=5)\n",
        "\n",
        "      #getting face detection results\n",
        "      faces = response.face_annotations\n",
        "\n",
        "      if not faces:\n",
        "        #print(\"No face detected\")\n",
        "        return None\n",
        "\n",
        "      #print(\"face detecteded\")\n",
        "      return \"Face detected\"\n",
        "\n",
        "  except Exception as e:\n",
        "      #print(f\"Error processing {image_path}: {e}\")\n",
        "      return None\n",
        "\n",
        "\n",
        "all_results = process_all_images(image_dir)\n",
        "print(\"Sample stored results:\",len(all_results))"
      ],
      "metadata": {
        "id": "qxdSOF7eqU0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "4b3d7187-96f0-47d2-ba94-51cd52ddaa07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f997676f4792>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_all_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample stored results:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f997676f4792>\u001b[0m in \u001b[0;36mprocess_all_images\u001b[0;34m(image_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#print(f\"Processing: {image_path}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_gender_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f997676f4792>\u001b[0m in \u001b[0;36mget_gender_prediction\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;31m#creating a vision API request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;31m#getting face detection results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_helpers/decorators.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(self, image, max_results, retry, timeout, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mcopied_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_results\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopied_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         response = self.annotate_image(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_helpers/__init__.py\u001b[0m in \u001b[0;36mannotate_image\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         r = self.batch_annotate_images(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mrequests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_v1/services/image_annotator/client.py\u001b[0m in \u001b[0;36mbatch_annotate_images\u001b[0;34m(self, request, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    808\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/vision_v1/services/image_annotator/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/tag.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/operation.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_cls, key, value)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(list(all_results.items()), columns= [\"Image\", \"FaceDetected\"])\n",
        "print(df_results.head())\n",
        "print(df_results.info())\n",
        "\n",
        "print(\"checking all results\")\n",
        "print(list(all_results.items())[:10])\n",
        "\n",
        "\n",
        "#Saving to a csv\n",
        "df_results.to_csv(\"face_detection_results.csv\", index=False)\n",
        "\n",
        "print(\"Results saved to face_detection_results.csv\")\n",
        "face_count = df_results[\"FaceDetected\"].value_counts()\n",
        "print(face_count)\n"
      ],
      "metadata": {
        "id": "MupKqfoUuWxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8af5e91-e8bf-4bfc-d1f9-567f62b022e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Image, FaceDetected]\n",
            "Index: []\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 0 entries\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Image         0 non-null      object\n",
            " 1   FaceDetected  0 non-null      object\n",
            "dtypes: object(2)\n",
            "memory usage: 132.0+ bytes\n",
            "None\n",
            "checking all results\n",
            "[]\n",
            "Results saved to face_detection_results.csv\n",
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('sample results from all results directory')\n",
        "print(list(all_results.items())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeCD7Yr3YPe0",
        "outputId": "98d2c0e4-f3f9-46ca-a814-b8ed6bb285e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample results from all results directory\n",
            "[]\n"
          ]
        }
      ]
    }
  ]
}